1) Duration that serves meaning

Target 20–60s, but let the segment stretch if it preserves a complete idea.

Start at a hook boundary and end at a semantic stop (answer delivered, punchline, or clear cliffhanger).

Prefer 2–3 scene or speaker changes per short; penalize >6 hard cuts.

2) Stronger signals for “good moments”

Speech dynamics: high energy, rising pitch, faster rate, low pause density in first 3–5s.

Lexical hooks: questions, bold claims, “How to…”, “X vs Y”, numerals, controversy cues.

Visual cues: close face box near center, stable framing, hands visible.

Structure: Q→A arcs, story beats, “setup→payoff”, list items.

Sentiment/affect: high valence or rapid change.

Scene novelty: new topic vs repetition using embedding distance.

3) Chapter-aware mining

Skip only intro chapter (you have this).

Within each non-intro chapter, run a local search for 1–3 best segments.

If a chapter yields nothing, hop adaptively: jump min(180s, 25% of chapter length) and recheck.

4) Audience attention proxies

Public signal fallback: parse comment timestamps (e.g., “12:34”) and cluster them to form hotspot priors.

Subtitle spikes: bursts of words/second and interjection tokens.

Combine as priors, not absolutes.

5) TikTok-specific polish

First 1.5–2.0s must include the hook text overlay and a punchy cut-in.

Avoid lower 15% and upper 10% for key text; keep faces off bottom 15%.

Auto-end on semantic cadence plus micro-tease or CTA if natural.

Burn concise subtitles, max ~2 lines, 42–48 chars/line, no widows.

6) Smarter segmentation

Start candidates at hooky words or strong intonation shifts.

Extend until one of: payoff reached, 28–38s sweet spot, or 60s hard cap.

If payoff comes late, allow up to 60s if score rises; if payoff comes early, end ~30s.

7) “No capture? Move on” but smarter

If two consecutive windows score below threshold, jump larger (e.g., +240s) once, then resume normal hops.

8) Multi-score ranking

Score with a weighted blend; learn weights over time from your own publish metrics.

Hook strength

Retention likelihood

Clarity/coherence

Visual quality

Novelty

Comment/retention priors

Safety/brand risk

9) Quality guards

Discard if first 3s have no voice and no on-screen text.

Discard if average face confidence low and no b-roll/text to carry meaning.

Loudness normalize to −14 LUFS, duck music under speech.

10) Explainable rationale

Store top 3 reasons a segment ranked high. Helps manual review and future training.

Concrete scoring v2.0
score = 0.28*hook + 0.18*retention + 0.16*clarity + 0.12*visual + 0.10*novelty + 0.10*engagementPriors + 0.06*safety


hook: LLM rubric on first 5s transcript + prosody

retention: predicted with small features (speech rate, pause density, Q→A presence, cut density)

clarity: WER, filler ratio, stray pronouns without referents

visual: face stability, body-aware framing coverage, motion smoothness

novelty: embedding distance from previous minutes

engagementPriors: retention hotspots or comment clusters

safety: profanity/brand risk negatives

Schema additions

Video.retentionHotspotsJson

Video.commentTimestampHotspotsJson

Clip.rationaleShort

Clip.featuresJson

Clip.durationChoice enum: short30 | mid45 | long60

Implementation slices
A) Adaptive duration selector
type Bound = { t: number }
type Segment = { start: number, end: number, transcript: string }
type Features = { hook: number, payoff: number, clarity: number, cutDensity: number }
type Choice = { start: number, end: number }

export function chooseClipWindow(cands: Segment[], f: Map<string, number>): Choice[] {
  const res: Choice[] = []
  for (const s of cands) {
    const hook = f.get(key(s, "hook")) || 0
    const payoff = f.get(key(s, "payoff")) || 0
    const clarity = f.get(key(s, "clarity")) || 0
    const cut = f.get(key(s, "cut")) || 0
    let start = s.start
    let end = Math.min(s.end, s.start + 60)
    let prefer = 30
    if (payoff > 0.7) {
      prefer = 45
    }
    if (hook > 0.8 && payoff > 0.8) {
      prefer = 60
    }
    const ideal = s.start + prefer
    if (ideal < end) {
      end = ideal
    }
    if (end - start < 20) {
      end = Math.min(s.end, s.start + 22)
    }
    if (clarity < 0.5) {
      end = Math.min(end, s.start + 35)
    }
    if (end - start >= 20) {
      res.push({ start, end })
    }
  }
  return res
}

function key(s: Segment, name: string): string {
  return `${s.start}-${s.end}-${name}`
}

B) Unified segment scoring
type Priors = { heat: number, comments: number }
type Visual = { faceStability: number, bodyCoverage: number, motionSmoothness: number }
type Text = { hook: number, clarity: number, novelty: number, safety: number, qaArc: number }
type Pred = { retention: number }

export function scoreSegment(pr: Priors, vi: Visual, tx: Text, pd: Pred): number {
  let score = 0
  score += 0.28 * tx.hook
  score += 0.18 * pd.retention
  score += 0.16 * tx.clarity
  score += 0.12 * vq(vi)
  score += 0.10 * tx.novelty
  score += 0.10 * Math.max(pr.heat, pr.comments)
  score += 0.06 * tx.safety
  return score
}

function vq(v: Visual): number {
  return 0.5 * v.faceStability + 0.3 * v.bodyCoverage + 0.2 * v.motionSmoothness
}

C) Comment timestamp mining (public fallback)
type YtComment = { text: string }
type Mark = { sec: number }
const tsRe = /(?<!\d)(\d{1,2}):(\d{2})(?::(\d{2}))?(?!\d)/g

export function mineTimestampsFromComments(cs: YtComment[]): number[] {
  const marks: number[] = []
  for (const c of cs) {
    const m = c.text.matchAll(tsRe)
    for (const g of m) {
      const h = g[3] ? parseInt(g[1], 10) : 0
      const mm = g[3] ? parseInt(g[2], 10) : parseInt(g[1], 10)
      const ss = g[3] ? parseInt(g[3], 10) : parseInt(g[2], 10)
      const sec = h * 3600 + mm * 60 + ss
      marks.push(sec)
    }
  }
  return clusterPeaks(marks, 30)
}

function clusterPeaks(xs: number[], windowSec: number): number[] {
  const s = xs.sort((a, b) => a - b)
  const peaks: number[] = []
  let acc: number[] = []
  for (const x of s) {
    if (acc.length === 0) {
      acc.push(x)
    } else {
      const last = acc[acc.length - 1]
      if (x - last <= windowSec) {
        acc.push(x)
      } else {
        peaks.push(median(acc))
        acc = [x]
      }
    }
  }
  if (acc.length > 0) {
    peaks.push(median(acc))
  }
  return peaks
}

function median(xs: number[]): number {
  const m = Math.floor(xs.length / 2)
  return xs.length % 2 ? xs[m] : Math.floor((xs[m - 1] + xs[m]) / 2)
}

D) Chapter-bounded sweeps with adaptive hops
type Chapter = { start: number, end: number, title: string }
type Window = { start: number, end: number }

export function chapterWindows(chs: Chapter[], introIdx: number | null): Window[] {
  const ws: Window[] = []
  for (let i = 0; i < chs.length; i++) {
    if (introIdx !== null && i === introIdx) {
      continue
    }
    const c = chs[i]
    const span = c.end - c.start
    const step = Math.max(45, Math.floor(span * 0.1))
    let t = c.start
    while (t + 25 <= c.end) {
      ws.push({ start: t, end: Math.min(c.end, t + 75) })
      t += step
    }
  }
  return ws
}

How to use retention hotspots

If not available, use mineTimestampsFromComments as a weak prior. It won’t be perfect, but it meaningfully steers search.

Smart framing upgrades

Prefer body-centroid targeting you added; add a “gesture boost” by tracking landmark variance to keep animated speakers centered.

Penalize segments where the body centroid exits the safe zone >10% of the time.

Auto add a slow 3–5% push-in on low-motion clips to add life.

Better first-seconds policy

Hard rule: first 2s contain either a question, a bold statement, or a concise “This is how…”

If not present, prepend 300–500ms pre-roll inside the same sentence boundary to avoid cold cuts.

Audio cleanup

Loudness normalize to −14 LUFS

Gate noise between words

Auto-duck any background music −10 dB under speech

Ranking and diversity

After scoring, do a Maximal Marginal Relevance pass on transcript embeddings so selected clips are not near-duplicates.

Keep 1–2 per chapter max unless chapter is ≥20% of total duration.

Fail-fast and skip

If top two candidates in a 5-minute span score <0.55, jump +240s once, then resume +90s sweeps.

Minimal worker wiring

Compute features and priors during transcription and scene detect.

Run chapterWindows() to build windows.

Within each window, generate candidates aligned to word boundaries and strong prosody changes.

Score with scoreSegment().

Choose durations with chooseClipWindow().

Apply diversity filter, then render.

Practical defaults

Target duration: 30–45s, expand to 60s if payoff not yet delivered.

Hook threshold: 0.7

Min score to render: 0.58

Max clips per video: 6 by default

Extra ideas to try next

Calibrate weights from your own publish outcomes using a simple logistic regression on past clips' watch time and completion rate.

Detect “listicle” patterns (First, Second, Finally) and pull self-contained list items.

Detect screen-share segments and auto overlay zoomed ROI boxes.

Auto-generate a 1-line title and 3–5 tags per clip, store rationaleShort for audit.