{"file_contents":{"src/services/youtube.ts":{"content":"import { spawn } from 'child_process'\nimport { promisify } from 'util'\nimport { exec } from 'child_process'\nimport { existsSync, writeFileSync, mkdirSync, chmodSync, unlinkSync } from 'fs'\nimport { join } from 'path'\nimport { tmpdir } from 'os'\nimport { prisma } from '@/src/lib/prisma'\nimport { decrypt } from '@/src/lib/encryption'\n\nconst execPromise = promisify(exec)\n\ntype DownloadInfo = {\n  file: string\n  height: number\n  fps: number\n  tbr: number\n  vcodec: string\n  acodec: string\n}\n\nfunction run(cmd: string, args: string[]): Promise<{ stdout: string, stderr: string }> {\n  return new Promise((resolve, reject) => {\n    const p = spawn(cmd, args, { stdio: ['ignore', 'pipe', 'pipe'] })\n    let out = ''\n    let err = ''\n    p.stdout.on('data', d => out += d.toString())\n    p.stderr.on('data', d => err += d.toString())\n    p.on('close', code => {\n      if (code === 0)\n      {\n        resolve({ stdout: out, stderr: err })\n      }\n      else\n      {\n        reject(new Error(err || `exit ${code}`))\n      }\n    })\n  })\n}\n\nexport async function downloadBest(url: string, cookiesPath?: string): Promise<DownloadInfo> {\n  const outDir = tmpdir()\n  const outTpl = join(outDir, '%(id)s.%(ext)s')\n  const ytdlp = await findYtDlp()\n  const args = [\n    '-j',\n    '--no-simulate',\n    '-f', 'bv*[height<=2160][ext=mp4]+ba[ext=m4a]/bv*[height<=2160]+ba/b',\n    '-S', 'res,fps,br,codec:h264:av01:vp9',\n    '--merge-output-format', 'mp4',\n    '--verbose',\n    '-o', outTpl,\n    url\n  ]\n  if (cookiesPath && cookiesPath.length > 0)\n  {\n    args.splice(1, 0, '--cookies', cookiesPath)\n  }\n  console.log('yt-dlp command:', ytdlp, args.join(' '))\n  const { stdout, stderr } = await run(ytdlp, args)\n  if (stderr && stderr.length > 0)\n  {\n    console.log('yt-dlp stderr:', stderr.substring(0, 2000))\n  }\n  const lines = stdout.trim().split('\\n')\n  const last = JSON.parse(lines[lines.length - 1])\n  const file = last['_filename']\n  const rf = (last['requested_formats'] && last['requested_formats'][0]) || last\n  const height = Number(rf['height'] || 0)\n  const fps = Number(rf['fps'] || 0)\n  const tbr = Number(rf['tbr'] || 0)\n  const vcodec = String(rf['vcodec'] || '')\n  const acodec = String(rf['acodec'] || '')\n  console.log(`Downloaded: ${height}p ${fps}fps ${vcodec} @ ${tbr}kbps`)\n  return { file, height, fps, tbr, vcodec, acodec }\n}\n\nexport async function createUserCookiesFile(userId: string): Promise<string | null> {\n  const user = await prisma.user.findUnique({\n    where: { id: userId },\n    select: { youtubeCookies: true }\n  })\n  \n  if (!user || !user.youtubeCookies)\n  {\n    return null\n  }\n  \n  const cookiesDir = join(tmpdir(), 'yt-cookies')\n  \n  if (!existsSync(cookiesDir))\n  {\n    mkdirSync(cookiesDir, { recursive: true })\n  }\n  \n  const cookiesPath = join(cookiesDir, `${userId}.txt`)\n  const decryptedCookies = decrypt(user.youtubeCookies)\n  \n  try {\n    writeFileSync(cookiesPath, decryptedCookies)\n    chmodSync(cookiesPath, 0o600)\n  }\n  catch (error: any) {\n    if (error?.errno === -122)\n    {\n      throw new Error('Temporary storage is full. Please try again in a few moments.')\n    }\n    throw error\n  }\n  \n  await prisma.user.update({\n    where: { id: userId },\n    data: { youtubeCookiesLastUsedAt: new Date() }\n  })\n  \n  return cookiesPath\n}\n\nexport function cleanupUserCookiesFile(userId: string): void {\n  const cookiesPath = join(tmpdir(), 'yt-cookies', `${userId}.txt`)\n  \n  try {\n    if (existsSync(cookiesPath))\n    {\n      unlinkSync(cookiesPath)\n    }\n  }\n  catch (error) {\n    console.error('Failed to cleanup cookies file:', error)\n  }\n}\n\nasync function findYtDlp(): Promise<string> {\n  if (process.env.YT_DLP_PATH && existsSync(process.env.YT_DLP_PATH))\n  {\n    return process.env.YT_DLP_PATH\n  }\n  \n  try {\n    await execPromise('which yt-dlp')\n    return 'yt-dlp'\n  }\n  catch {\n    try {\n      await execPromise('which youtube-dl')\n      return 'youtube-dl'\n    }\n    catch {\n      throw new Error('yt-dlp or youtube-dl not found in PATH')\n    }\n  }\n}\n\nexport interface Chapter {\n  title: string\n  start_time?: number\n  end_time?: number\n  startSec: number\n  endSec: number\n}\n\ninterface VideoMetadata {\n  id: string\n  title: string\n  duration: number\n  chapters: Chapter[]\n}\n\nexport async function getVideoMetadata(url: string, userId: string): Promise<VideoMetadata> {\n  const ytdlp = await findYtDlp()\n  const cookiesPath = await createUserCookiesFile(userId)\n  const args = [\n    '--dump-json',\n    '--no-playlist',\n    url\n  ]\n  \n  if (cookiesPath)\n  {\n    args.splice(0, 0, '--cookies', cookiesPath)\n  }\n  \n  const { stdout } = await run(ytdlp, args)\n  const metadata = JSON.parse(stdout)\n  \n  const chapters = (metadata.chapters || []).map((ch: any) => ({\n    title: ch.title,\n    start_time: ch.start_time,\n    end_time: ch.end_time,\n    startSec: ch.start_time,\n    endSec: ch.end_time\n  }))\n  \n  return {\n    id: metadata.id || '',\n    title: metadata.title || 'Unknown',\n    duration: metadata.duration || 0,\n    chapters\n  }\n}\n\nexport async function downloadVideo(url: string, outputPath: string, userId: string): Promise<DownloadInfo> {\n  const cookiesPath = await createUserCookiesFile(userId)\n  let info: DownloadInfo | null = null\n  let videoId: string | null = null\n  \n  try {\n    const metadata = await getVideoMetadata(url, userId)\n    videoId = metadata.id\n    \n    info = await downloadBest(url, cookiesPath || undefined)\n    \n    if (info.file.length === 0)\n    {\n      throw new Error('no file downloaded')\n    }\n    \n    const { rename } = await import('fs/promises')\n    await rename(info.file, outputPath)\n    return info\n  }\n  finally {\n    if (videoId)\n    {\n      cleanupYtDlpTempFiles(videoId)\n    }\n  }\n}\n\nfunction cleanupYtDlpTempFiles(videoId: string): void {\n  const { readdirSync, rmSync } = require('fs')\n  const tmp = tmpdir()\n  \n  try {\n    const files = readdirSync(tmp)\n    let cleaned = 0\n    \n    for (const file of files)\n    {\n      if (file.startsWith(videoId) && file.match(/\\.(webm|mp4|m4a|part)$/))\n      {\n        try {\n          rmSync(join(tmp, file), { force: true })\n          cleaned++\n        }\n        catch (err) {\n          console.error(`Failed to cleanup temp file ${file}:`, err)\n        }\n      }\n    }\n    \n    if (cleaned > 0)\n    {\n      console.log(`Cleaned up ${cleaned} temp files for video ${videoId}`)\n    }\n  }\n  catch (err) {\n    console.error('Failed to cleanup yt-dlp temp files:', err)\n  }\n}\n","size_bytes":6408},"app/api/auth/login/route.ts":{"content":"import { NextResponse } from 'next/server'\nimport { getSession } from '@/src/lib/session'\nimport { checkYouTubeConnection } from '@/src/lib/youtube-client'\n\nexport async function POST() {\n  try {\n    const youtubeConnected = await checkYouTubeConnection()\n    \n    if (!youtubeConnected)\n    {\n      return NextResponse.json(\n        { error: 'YouTube connection not configured. Please set up the YouTube connector first.' },\n        { status: 401 }\n      )\n    }\n    \n    const session = await getSession()\n    session.isAuthenticated = true\n    session.userId = 'youtube_user'\n    await session.save()\n    \n    return NextResponse.json({ success: true })\n  }\n  catch (error) {\n    return NextResponse.json(\n      { error: 'Failed to authenticate with YouTube' },\n      { status: 500 }\n    )\n  }\n}\n","size_bytes":799},"src/worker.ts":{"content":"import { Worker, Job } from \"bullmq\";\nimport { connection } from \"./lib/queue\";\nimport { prisma } from \"./lib/prisma\";\nimport {\n  getVideoMetadata,\n  downloadVideo,\n  cleanupUserCookiesFile,\n} from \"./services/youtube\";\nimport {\n  extractAudio,\n  compressAudioForTranscription,\n  renderVerticalClip,\n  renderSmartFramedClip,\n  extractThumbnail,\n  createSrtFile,\n  detectScenes,\n  probeBitrate,\n  probeVideo,\n} from \"./services/ffmpeg\";\nimport { transcribeAudio } from \"./services/openai\";\nimport { scoreClip } from \"./services/openai\";\nimport { detectSegments } from \"./services/segmentation\";\nimport {\n  detectEnhancedSegments,\n  mineTimestampsFromComments,\n} from \"./services/segmentation-v2\";\nimport { uploadFile } from \"./services/s3\";\nimport { join } from \"path\";\nimport { mkdirSync, existsSync, rmSync } from \"fs\";\nimport { tmpdir } from \"os\";\nimport { cleanupTempFiles } from \"./lib/cleanup\";\nimport {\n  computeCropMap,\n  buildPiecewiseExpr,\n  Constraints,\n} from \"./services/framingService\";\n\ninterface VideoJob {\n  videoId: string;\n  userId: string;\n}\n\nasync function checkCancelled(videoId: string) {\n  const video = await prisma.video.findUnique({\n    where: { id: videoId },\n    select: { status: true },\n  });\n\n  if (video?.status === \"cancelled\") {\n    throw new Error(\"Video processing was cancelled by user\");\n  }\n}\n\nasync function processVideo(job: Job<VideoJob>) {\n  const { videoId, userId } = job.data;\n\n  if (!userId) {\n    throw new Error(\"User ID is required for video processing\");\n  }\n\n  await prisma.video.update({\n    where: { id: videoId },\n    data: { status: \"processing\" },\n  });\n\n  const video = await prisma.video.findUnique({\n    where: { id: videoId },\n    include: { user: true },\n  });\n\n  if (!video) {\n    throw new Error(`Video ${videoId} not found`);\n  }\n\n  if (!video.user.youtubeCookies) {\n    throw new Error(\n      \"YouTube cookies not configured. Please upload your YouTube cookies.\",\n    );\n  }\n\n  const workDir = join(tmpdir(), `video_${videoId}`);\n\n  if (!existsSync(workDir)) {\n    mkdirSync(workDir, { recursive: true });\n  }\n\n  try {\n    const videoPath = join(workDir, \"source.mp4\");\n    const audioPath = join(workDir, \"audio.m4a\");\n    const transcriptionAudioPath = join(workDir, \"audio_transcription.mp3\");\n\n    console.log(`Fetching video metadata for chapters`);\n    const metadata = await getVideoMetadata(video.sourceUrl, userId);\n    console.log(`Found ${metadata.chapters.length} chapters`);\n\n    if (metadata.chapters.length > 0) {\n      metadata.chapters.forEach((ch, i) => {\n        console.log(\n          `  Chapter ${i + 1}: ${ch.title} (${ch.startSec.toFixed(1)}s - ${ch.endSec.toFixed(1)}s)`,\n        );\n      });\n    }\n\n    await checkCancelled(videoId);\n\n    console.log(`Downloading video: ${video.sourceUrl}`);\n    const sourceInfo = await downloadVideo(video.sourceUrl, videoPath, userId);\n    console.log(\n      `Source: ${sourceInfo.height}p ${sourceInfo.fps}fps ${sourceInfo.vcodec} @ ${sourceInfo.tbr}kbps`,\n    );\n\n    await checkCancelled(videoId);\n\n    console.log(`Validating source quality`);\n    const br = await probeBitrate(videoPath);\n    console.log(\n      `Measured bitrate: ${br.kbps.toFixed(0)} kbps, size: ${(br.size / 1024 / 1024).toFixed(1)} MB, duration: ${br.seconds.toFixed(1)}s`,\n    );\n\n    const minBitrate =\n      sourceInfo.height >= 1080 ? 3000 : sourceInfo.height >= 720 ? 1500 : 1000;\n\n    if (br.kbps < minBitrate) {\n      console.warn(\n        `⚠️  Quality Gate: Source bitrate ${br.kbps.toFixed(0)} kbps is below recommended ${minBitrate} kbps for ${sourceInfo.height}p`,\n      );\n    } else {\n      console.log(\n        `✓ Quality Gate: Source quality meets ${sourceInfo.height}p standards (${br.kbps.toFixed(0)} >= ${minBitrate} kbps)`,\n      );\n    }\n\n    await checkCancelled(videoId);\n\n    console.log(`Extracting audio`);\n    await extractAudio(videoPath, audioPath);\n\n    console.log(`Compressing audio for transcription`);\n    await compressAudioForTranscription(audioPath, transcriptionAudioPath);\n\n    await checkCancelled(videoId);\n\n    console.log(`Transcribing audio`);\n    const transcript = await transcribeAudio(\n      transcriptionAudioPath,\n      metadata.chapters,\n    );\n\n    await checkCancelled(videoId);\n\n    await prisma.video.update({\n      where: { id: videoId },\n      data: { transcript: transcript as any },\n    });\n\n    console.log(`Detecting scene changes`);\n    const sceneChanges = await detectScenes(videoPath);\n    console.log(`Found ${sceneChanges.length} scene changes`);\n\n    await checkCancelled(videoId);\n\n    let commentHotspots: number[] = [];\n\n    console.log(`Detecting segments with enhanced v2 algorithm`);\n    const segments = detectEnhancedSegments(\n      transcript,\n      sceneChanges,\n      metadata.chapters,\n      video.durationSec,\n      commentHotspots,\n    );\n\n    console.log(`Found ${segments.length} candidate segments`);\n\n    await checkCancelled(videoId);\n\n    const processSegment = async (segment: any, i: number) => {\n      await checkCancelled(videoId);\n\n      console.log(`Processing segment ${i + 1}/${segments.length}`);\n\n      const clipId = `clip_${Date.now()}_${videoId}_${i}`;\n      const clipDir = join(workDir, `clip_${i}`);\n\n      if (!existsSync(clipDir)) {\n        mkdirSync(clipDir, { recursive: true });\n      }\n\n      const clipPath = join(clipDir, \"clip.mp4\");\n      const thumbPath = join(clipDir, \"thumb.jpg\");\n      const srtPath = join(clipDir, \"clip.srt\");\n\n      const adjustedWords = segment.words.map((w: any) => ({\n        word: w.word,\n        start: w.start - segment.startSec,\n        end: w.end - segment.startSec,\n      }));\n\n      createSrtFile(adjustedWords, srtPath);\n\n      let cropMap = null;\n      let smartFramed = false;\n\n      if (process.env.FEATURE_SMART_FRAMING === \"true\") {\n        try {\n          const probe = await probeVideo(videoPath);\n          const constraints: Constraints = {\n            margin: Number(process.env.FRAMING_SAFETY_MARGIN || 0.12),\n            maxPan: Number(process.env.FRAMING_MAX_PAN_PX_PER_S || 600),\n            easeMs: Number(process.env.FRAMING_EASE_MS || 250),\n            centerBiasY: Number(process.env.FRAMING_CENTER_BIAS_Y || 0.08),\n            safeTop: Number(process.env.FRAMING_TOP_SAFE_PCT || 0.1),\n            safeBottom: Number(process.env.FRAMING_BOTTOM_SAFE_PCT || 0.15),\n          };\n\n          const transcriptWords = segment.words.map((w: any) => ({\n            t: w.start,\n            end: w.end,\n            text: w.word,\n            speaker: w.speaker,\n          }));\n\n          cropMap = await computeCropMap(\n            {\n              videoPath,\n              baseW: probe.width,\n              baseH: probe.height,\n              segStart: segment.startSec,\n              segEnd: segment.endSec,\n              transcript: transcriptWords,\n            },\n            constraints,\n          );\n\n          if (cropMap) {\n            const exprX = buildPiecewiseExpr(cropMap, \"x\");\n            const exprY = buildPiecewiseExpr(cropMap, \"y\");\n            const cropW = Math.floor((probe.height * 9) / 16);\n            const cropH = probe.height;\n\n            await renderSmartFramedClip({\n              inputPath: videoPath,\n              outputPath: clipPath,\n              startTime: segment.startSec,\n              duration: segment.durationSec,\n              srtPath,\n              hookText: segment.hook,\n              cropMapExprX: exprX,\n              cropMapExprY: exprY,\n              cropW,\n              cropH,\n            });\n\n            smartFramed = true;\n            console.log(\n              `  Smart framing applied with ${cropMap.length} keyframes`,\n            );\n          }\n        } catch (err) {\n          console.error(\n            \"Smart framing failed, falling back to standard crop:\",\n            err,\n          );\n        }\n      }\n\n      if (!smartFramed) {\n        await renderVerticalClip({\n          inputPath: videoPath,\n          outputPath: clipPath,\n          startTime: segment.startSec,\n          duration: segment.durationSec,\n          srtPath,\n          hookText: segment.hook,\n        });\n      }\n\n      const clipBitrate = await probeBitrate(clipPath);\n      console.log(\n        `  Output: ${(clipBitrate.size / 1024 / 1024).toFixed(1)} MB @ ${clipBitrate.kbps.toFixed(0)} kbps`,\n      );\n\n      const [_, scores] = await Promise.all([\n        extractThumbnail(clipPath, thumbPath, 1),\n        scoreClip(video.title, segment.hook, segment.text),\n      ]);\n\n      const s3VideoKey = `videos/${videoId}/clips/${clipId}/clip.mp4`;\n      const s3ThumbKey = `videos/${videoId}/clips/${clipId}/thumb.jpg`;\n      const s3SrtKey = `videos/${videoId}/clips/${clipId}/clip.srt`;\n\n      await Promise.all([\n        uploadFile(s3VideoKey, clipPath, \"video/mp4\"),\n        uploadFile(s3ThumbKey, thumbPath, \"image/jpeg\"),\n        uploadFile(s3SrtKey, srtPath, \"text/plain\"),\n      ]);\n\n      await prisma.clip.create({\n        data: {\n          id: clipId,\n          videoId,\n          startSec: Math.floor(segment.startSec),\n          endSec: Math.floor(segment.endSec),\n          durationSec: Math.floor(segment.durationSec),\n          category: scores.category,\n          tags: scores.tags,\n          scoreHook: scores.scores.hook_strength,\n          scoreRetention: scores.scores.retention_likelihood,\n          scoreClarity: scores.scores.clarity,\n          scoreShare: scores.scores.shareability,\n          scoreOverall: scores.scores.overall,\n          rationale: scores.rationale,\n          rationaleShort: segment.rationaleShort || scores.rationale,\n          featuresJson: segment.features ? (segment.features as any) : null,\n          durationChoice: segment.durationChoice || null,\n          s3VideoKey,\n          s3ThumbKey,\n          s3SrtKey,\n          smartFramed,\n          cropMapJson: cropMap ? (cropMap as any) : null,\n        },\n      });\n\n      console.log(`Segment ${i + 1} completed`);\n    };\n\n    const clipSuccesses: string[] = [];\n    const clipFailures: Array<{ index: number; error: any }> = [];\n\n    for (let i = 0; i < segments.length; i += 2) {\n      const batch = segments.slice(i, i + 2);\n      const results = await Promise.allSettled(\n        batch.map((seg, idx) => processSegment(seg, i + idx)),\n      );\n\n      for (let j = 0; j < results.length; j++) {\n        const result = results[j];\n        const clipIndex = i + j;\n\n        if (result.status === \"fulfilled\") {\n          clipSuccesses.push(`clip_${clipIndex}`);\n        } else {\n          console.error(`Clip ${clipIndex + 1} failed:`, result.reason);\n          clipFailures.push({ index: clipIndex, error: result.reason });\n        }\n      }\n    }\n\n    const summary = {\n      totalSegments: segments.length,\n      successfulClips: clipSuccesses.length,\n      failedClips: clipFailures.length,\n      failures: clipFailures.map((f) => ({\n        clip: `clip_${f.index}`,\n        error: f.error?.message || String(f.error),\n      })),\n    };\n\n    console.log(\"Processing summary:\", JSON.stringify(summary, null, 2));\n\n    await prisma.video.update({\n      where: { id: videoId },\n      data: { status: \"completed\" },\n    });\n\n    console.log(\n      `Video ${videoId} processing completed with ${clipSuccesses.length} successful clips and ${clipFailures.length} failures`,\n    );\n  } catch (error: any) {\n    console.error(`Error processing video ${videoId}:`, error);\n\n    if (error?.message?.includes(\"cancelled by user\")) {\n      console.log(\n        `Video ${videoId} was cancelled by user, keeping cancelled status`,\n      );\n    } else {\n      await prisma.video.update({\n        where: { id: videoId },\n        data: { status: \"failed\" },\n      });\n    }\n\n    throw error;\n  } finally {\n    cleanupUserCookiesFile(userId);\n\n    if (existsSync(workDir)) {\n      rmSync(workDir, { recursive: true, force: true });\n    }\n  }\n}\n\nconst worker = new Worker<VideoJob>(\"video.process\", processVideo, {\n  connection,\n  concurrency: 1,\n  lockDuration: 1800000,\n  lockRenewTime: 30000,\n});\n\nworker.on(\"completed\", (job) => {\n  console.log(`Job ${job.id} completed`);\n});\n\nworker.on(\"failed\", (job, err) => {\n  console.error(`Job ${job?.id} failed:`, err);\n});\n\ncleanupTempFiles();\nconsole.log(\"Worker started\");\n","size_bytes":12206},"app/api/auth/google/start/route.ts":{"content":"import { NextResponse } from 'next/server'\nimport { OAuth2Client } from 'google-auth-library'\n\nconst getOAuthClient = () => {\n  const clientId = process.env.GOOGLE_CLIENT_ID\n  const clientSecret = process.env.GOOGLE_CLIENT_SECRET\n  \n  let redirectUri = process.env.GOOGLE_REDIRECT_URI\n  \n  if (!redirectUri)\n  {\n    const replitDomain = process.env.REPLIT_DOMAINS?.split(',')[0]\n    \n    if (replitDomain)\n    {\n      redirectUri = `https://${replitDomain}/api/auth/google/callback`\n    }\n    else\n    {\n      redirectUri = 'http://localhost:5000/api/auth/google/callback'\n    }\n  }\n  \n  if (!clientId || !clientSecret)\n  {\n    throw new Error('Google OAuth credentials not configured')\n  }\n  \n  return new OAuth2Client(clientId, clientSecret, redirectUri)\n}\n\nexport async function GET() {\n  try {\n    const oauth2Client = getOAuthClient()\n    \n    const authUrl = oauth2Client.generateAuthUrl({\n      access_type: 'offline',\n      scope: [\n        'https://www.googleapis.com/auth/youtube.readonly',\n        'https://www.googleapis.com/auth/userinfo.email',\n        'https://www.googleapis.com/auth/userinfo.profile',\n        'openid'\n      ],\n      prompt: 'consent'\n    })\n    \n    return NextResponse.json({ authUrl })\n  }\n  catch (error: any) {\n    console.error('Error generating OAuth URL:', error)\n    return NextResponse.json(\n      { error: 'Failed to generate OAuth URL' },\n      { status: 500 }\n    )\n  }\n}\n","size_bytes":1419},"next-env.d.ts":{"content":"/// <reference types=\"next\" />\n/// <reference types=\"next/image-types/global\" />\n\n// NOTE: This file should not be edited\n// see https://nextjs.org/docs/basic-features/typescript for more information.\n","size_bytes":201},"postcss.config.js":{"content":"module.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n}\n","size_bytes":82},"src/lib/rate-limit.ts":{"content":"import rateLimit from 'express-rate-limit'\n\nexport const apiLimiter = rateLimit({\n  windowMs: 15 * 60 * 1000,\n  max: 100,\n  standardHeaders: true,\n  legacyHeaders: false,\n  message: 'Too many requests from this IP, please try again later.'\n})\n\nexport const authLimiter = rateLimit({\n  windowMs: 15 * 60 * 1000,\n  max: 5,\n  standardHeaders: true,\n  legacyHeaders: false,\n  message: 'Too many authentication attempts, please try again later.'\n})\n","size_bytes":444},"app/login/page.tsx":{"content":"'use client'\n\nimport { useState, useEffect } from 'react'\nimport { useRouter, useSearchParams } from 'next/navigation'\n\nexport default function LoginPage() {\n  const [loading, setLoading] = useState(false)\n  const [error, setError] = useState('')\n  const router = useRouter()\n  const searchParams = useSearchParams()\n\n  useEffect(() => {\n    checkAuth()\n    \n    const errorParam = searchParams.get('error')\n    \n    if (errorParam)\n    {\n      setError('Authentication failed. Please try again.')\n    }\n  }, [searchParams])\n\n  async function checkAuth() {\n    try {\n      const res = await fetch('/api/auth/status')\n      const data = await res.json()\n      \n      if (data.isAuthenticated)\n      {\n        const connectionsRes = await fetch('/api/me/connections')\n        const connections = await connectionsRes.json()\n        \n        if (connections.hasCookies)\n        {\n          router.push('/')\n        }\n        else\n        {\n          router.push('/setup-cookies')\n        }\n      }\n    }\n    catch (err) {\n      console.error('Failed to check auth status:', err)\n    }\n  }\n\n  async function handleGoogleLogin() {\n    setLoading(true)\n    setError('')\n    \n    try {\n      const res = await fetch('/api/auth/google/start')\n      const data = await res.json()\n      \n      if (!res.ok)\n      {\n        throw new Error(data.error || 'Failed to start OAuth flow')\n      }\n      \n      window.location.href = data.authUrl\n    }\n    catch (err: any) {\n      setError(err.message || 'Failed to initiate Google login')\n      setLoading(false)\n    }\n  }\n\n  return (\n    <div className=\"min-h-screen bg-gray-900 text-white flex items-center justify-center p-4\">\n      <div className=\"max-w-md w-full bg-gray-800 rounded-lg shadow-xl p-8\">\n        <h1 className=\"text-3xl font-bold mb-2\">YT Shortsmith</h1>\n        <p className=\"text-gray-400 mb-8\">Sign in with Google to continue</p>\n        \n        {error && (\n          <div className=\"mb-6 p-4 bg-red-900/50 border border-red-700 rounded-lg\">\n            <p className=\"text-red-200 text-sm\">{error}</p>\n          </div>\n        )}\n        \n        <button\n          onClick={handleGoogleLogin}\n          disabled={loading}\n          className=\"w-full bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 disabled:cursor-not-allowed text-white font-semibold py-3 px-4 rounded-lg transition-colors flex items-center justify-center gap-2\"\n        >\n          {loading ? (\n            'Redirecting...'\n          ) : (\n            <>\n              <svg className=\"w-5 h-5\" viewBox=\"0 0 24 24\" fill=\"currentColor\">\n                <path d=\"M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z\" fill=\"#4285F4\"/>\n                <path d=\"M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z\" fill=\"#34A853\"/>\n                <path d=\"M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z\" fill=\"#FBBC05\"/>\n                <path d=\"M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z\" fill=\"#EA4335\"/>\n              </svg>\n              Sign in with Google\n            </>\n          )}\n        </button>\n        \n        <div className=\"mt-8 pt-6 border-t border-gray-700\">\n          <h2 className=\"font-semibold mb-2\">What happens next?</h2>\n          <ul className=\"text-sm text-gray-400 space-y-2\">\n            <li className=\"flex items-start gap-2\">\n              <span className=\"text-blue-400 mt-0.5\">1.</span>\n              <span>Sign in with your Google account</span>\n            </li>\n            <li className=\"flex items-start gap-2\">\n              <span className=\"text-blue-400 mt-0.5\">2.</span>\n              <span>Upload your YouTube cookies for video access</span>\n            </li>\n            <li className=\"flex items-start gap-2\">\n              <span className=\"text-blue-400 mt-0.5\">3.</span>\n              <span>Start creating short clips from YouTube videos</span>\n            </li>\n          </ul>\n        </div>\n      </div>\n    </div>\n  )\n}\n","size_bytes":4214},"src/services/openai.ts":{"content":"import OpenAI from 'openai'\nimport { createReadStream, statSync } from 'fs'\nimport { getFileSizeBytes, getDurationSeconds } from './ffmpeg'\nimport ffmpeg from 'fluent-ffmpeg'\nimport ffmpegPath from 'ffmpeg-static'\nimport { join } from 'path'\n\nffmpeg.setFfmpegPath(ffmpegPath!)\n\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n  timeout: 600000,\n  maxRetries: 3\n})\n\nexport interface TranscriptWord {\n  word: string\n  start: number\n  end: number\n}\n\nexport interface TranscriptSegment {\n  text: string\n  start: number\n  end: number\n  words: TranscriptWord[]\n  language?: string\n}\n\nconst TARGET_MB = parseFloat(process.env.OPENAI_CHUNK_TARGET_MB || '24.5')\nconst TARGET_BYTES = Math.floor(TARGET_MB * 1024 * 1024)\nconst MAX_RETRIES = parseInt(process.env.OPENAI_MAX_RETRIES || '2', 10)\n\nexport async function withRetries<T>(fn: () => Promise<T>): Promise<T> {\n  let attempt = 0\n  let delay = 1000\n  \n  for (;;)\n  {\n    try {\n      const res = await fn()\n      return res\n    }\n    catch (err: any) {\n      attempt = attempt + 1\n      const code = err?.status || err?.code || 0\n      const transient = code === 429 || code === 408 || code === 500 || code === 502 || code === 503 || code === 504\n      \n      if (attempt > MAX_RETRIES)\n      {\n        throw err\n      }\n      \n      if (!transient)\n      {\n        throw err\n      }\n      \n      await new Promise(r => {\n        setTimeout(r, delay)\n      })\n      delay = delay * 2\n    }\n  }\n}\n\nexport async function planAudioChunksBySize(inputPath: string, durationSec: number): Promise<{ start: number; duration: number }[]> {\n  const sizeBytes = getFileSizeBytes(inputPath)\n  let chunks = Math.ceil(sizeBytes / TARGET_BYTES)\n  \n  if (chunks < 1)\n  {\n    chunks = 1\n  }\n  \n  const base = Math.floor(durationSec / chunks)\n  const rem = durationSec - base * chunks\n  const plan: { start: number; duration: number }[] = []\n  let cursor = 0\n  \n  for (let i = 0; i < chunks; i++)\n  {\n    let d = base\n    \n    if (i < rem)\n    {\n      d = d + 1\n    }\n    \n    plan.push({ start: cursor, duration: d })\n    cursor = cursor + d\n  }\n  \n  return plan\n}\n\nasync function extractAudioChunk(inputPath: string, outputPath: string, start: number, duration: number): Promise<void> {\n  return new Promise((resolve, reject) => {\n    ffmpeg(inputPath)\n      .setStartTime(start)\n      .duration(duration)\n      .outputOptions(['-c:a', 'copy'])\n      .output(outputPath)\n      .on('end', () => resolve())\n      .on('error', reject)\n      .run()\n  })\n}\n\nasync function transcribeAudioFile(audioPath: string, timeOffset: number = 0, retries = 5): Promise<{ words: TranscriptWord[], language: string }> {\n  let lastError: Error | null = null\n  \n  for (let attempt = 1; attempt <= retries; attempt++)\n  {\n    try {\n      const response = await openai.audio.transcriptions.create({\n        file: createReadStream(audioPath),\n        model: 'whisper-1',\n        response_format: 'verbose_json',\n        timestamp_granularities: ['word']\n      })\n\n      const words: TranscriptWord[] = []\n      \n      if (response.words)\n      {\n        for (const word of response.words)\n        {\n          words.push({\n            word: word.word,\n            start: word.start + timeOffset,\n            end: word.end + timeOffset\n          })\n        }\n      }\n      \n      const detectedLanguage = response.language || 'en'\n      console.log(`Detected language: ${detectedLanguage}`)\n      \n      return { words, language: detectedLanguage }\n    }\n    catch (error: any) {\n      lastError = error\n      \n      if (error.code === 'ECONNRESET' || error.cause?.code === 'ECONNRESET' || error.status === 500 || error.status === 503)\n      {\n        const delay = Math.min(1000 * Math.pow(2, attempt - 1), 30000)\n        console.log(`Transcription attempt ${attempt}/${retries} failed with network error. Retrying in ${delay}ms...`)\n        await new Promise(resolve => setTimeout(resolve, delay))\n        continue\n      }\n      \n      throw error\n    }\n  }\n  \n  throw lastError || new Error('Failed to transcribe audio after retries')\n}\n\nfunction isIntroChapter(title: string, detectedLanguage?: string): boolean {\n  const titleLower = title.toLowerCase().trim()\n  \n  const introKeywords: Record<string, string[]> = {\n    'en': ['intro', 'introduction', 'opening', 'welcome', 'trailer', 'credits'],\n    'es': ['intro', 'introduccion', 'introducci\\u00f3n', 'apertura', 'inicio', 'inicio del video', 'inicio del v\\u00eddeo', 'bienvenida'],\n    'pt': ['intro', 'introducao', 'introdu\\u00e7ao', 'introdu\\u00e7\\u00e3o', 'apresentacao', 'apresenta\\u00e7ao', 'apresenta\\u00e7\\u00e3o', 'abertura', 'boas-vindas'],\n    'fr': ['intro', 'introduction', 'ouverture', 'bienvenue'],\n    'de': ['intro', 'einf\\u00fchrung', 'einleitung', 'er\\u00f6ffnung', 'willkommen'],\n    'it': ['intro', 'introduzione', 'apertura', 'benvenuto'],\n    'ja': ['イントロ', '紹介', 'オープニング'],\n    'ko': ['인트로', '소개', '오프닝'],\n    'zh': ['介绍', '简介', '开场'],\n    'ru': ['вступление', 'введение', 'открытие']\n  }\n  \n  let keywordsToCheck = introKeywords['en'] || []\n  \n  if (detectedLanguage && introKeywords[detectedLanguage])\n  {\n    keywordsToCheck = [...introKeywords[detectedLanguage], ...introKeywords['en']]\n  }\n  else {\n    keywordsToCheck = Object.values(introKeywords).flat()\n  }\n  \n  for (const keyword of keywordsToCheck)\n  {\n    if (titleLower.includes(keyword))\n    {\n      return true\n    }\n  }\n  \n  if (titleLower.length < 20 && (titleLower.match(/^(chapter|cap[íi]tulo|part|parte|section|se[cç][aã]o|episode|epis[óo]dio)\\s*[0-9]+/)))\n  {\n    return false\n  }\n  \n  return false\n}\n\nfunction calculateIntroSkip(chapters: any[], duration: number): number {\n  const defaultSkip = parseInt(process.env.INTRO_SKIP_SECONDS || '180', 10)\n  \n  if (!chapters || chapters.length === 0)\n  {\n    console.log(`No chapters found, using default skip: ${defaultSkip}s`)\n    return defaultSkip\n  }\n  \n  const firstChapter = chapters[0]\n  \n  if (isIntroChapter(firstChapter.title))\n  {\n    const chapterEnd = firstChapter.endSec || firstChapter.end_time || 0\n    console.log(`First chapter \"${firstChapter.title}\" detected as intro, skipping to ${chapterEnd}s`)\n    return chapterEnd\n  }\n  \n  console.log(`First chapter \"${firstChapter.title}\" not detected as intro, processing from start`)\n  return 0\n}\n\nexport async function transcribeAudio(audioPath: string, chapters: any[] = []): Promise<TranscriptSegment[]> {\n  const fileSize = getFileSizeBytes(audioPath)\n  const duration = await getDurationSeconds(audioPath)\n  \n  const introSkip = calculateIntroSkip(chapters, duration)\n  \n  let effectiveStart = 0\n  \n  if (duration > introSkip)\n  {\n    effectiveStart = introSkip\n    console.log(`Skipping first ${introSkip}s of audio (intro skip)`)\n  }\n  \n  const effectiveDuration = duration - effectiveStart\n  let allWords: TranscriptWord[] = []\n  let detectedLanguage = 'en'\n  \n  if (fileSize > TARGET_BYTES)\n  {\n    console.log(`Audio file is ${(fileSize / 1024 / 1024).toFixed(1)}MB, splitting into chunks...`)\n    const chunkPlan = await planAudioChunksBySize(audioPath, effectiveDuration)\n    \n    console.log(`Transcribing ${chunkPlan.length} chunks in parallel (max 3 concurrent)...`)\n    \n    const audioDir = audioPath.substring(0, audioPath.lastIndexOf('/'))\n    const audioExt = audioPath.substring(audioPath.lastIndexOf('.'))\n    \n    const transcribeChunk = async (plan: { start: number; duration: number }, index: number) => {\n      console.log(`Transcribing chunk ${index + 1}/${chunkPlan.length}`)\n      const chunkPath = join(audioDir, `chunk_${index}${audioExt}`)\n      const absoluteStart = effectiveStart + plan.start\n      await extractAudioChunk(audioPath, chunkPath, absoluteStart, plan.duration)\n      return await transcribeAudioFile(chunkPath, absoluteStart)\n    }\n    \n    const chunkResults: { words: TranscriptWord[], language: string }[] = []\n    const chunkErrors: Array<{ index: number; error: any }> = []\n    \n    for (let i = 0; i < chunkPlan.length; i += 3)\n    {\n      const batch = chunkPlan.slice(i, i + 3)\n      const batchResults = await Promise.allSettled(\n        batch.map((plan, idx) => transcribeChunk(plan, i + idx))\n      )\n      \n      for (let j = 0; j < batchResults.length; j++)\n      {\n        const result = batchResults[j]\n        \n        if (result.status === 'fulfilled')\n        {\n          chunkResults.push(result.value)\n        }\n        else {\n          const chunkIndex = i + j\n          console.error(`Chunk ${chunkIndex + 1} failed to transcribe:`, result.reason)\n          chunkErrors.push({ index: chunkIndex, error: result.reason })\n        }\n      }\n    }\n    \n    if (chunkErrors.length > 0 && chunkResults.length === 0)\n    {\n      throw new Error(`All chunks failed to transcribe. Errors: ${JSON.stringify(chunkErrors)}`)\n    }\n    \n    if (chunkResults.length > 0)\n    {\n      detectedLanguage = chunkResults[0].language\n    }\n    \n    allWords = chunkResults.flatMap(r => r.words)\n  }\n  else {\n    let result: { words: TranscriptWord[], language: string }\n    \n    if (effectiveStart > 0)\n    {\n      const audioDir = audioPath.substring(0, audioPath.lastIndexOf('/'))\n      const audioExt = audioPath.substring(audioPath.lastIndexOf('.'))\n      const skippedPath = join(audioDir, `skipped${audioExt}`)\n      await extractAudioChunk(audioPath, skippedPath, effectiveStart, effectiveDuration)\n      result = await transcribeAudioFile(skippedPath, effectiveStart)\n    }\n    else {\n      result = await transcribeAudioFile(audioPath)\n    }\n    \n    allWords = result.words\n    detectedLanguage = result.language\n  }\n\n  const segments: TranscriptSegment[] = []\n  let currentSegment: TranscriptWord[] = []\n  let segmentStart = 0\n  let segmentText = ''\n  \n  for (let i = 0; i < allWords.length; i++)\n  {\n    const word = allWords[i]\n    \n    if (currentSegment.length === 0)\n    {\n      segmentStart = word.start\n    }\n    \n    currentSegment.push(word)\n    segmentText += word.word + ' '\n    \n    if (i < allWords.length - 1)\n    {\n      const gap = allWords[i + 1].start - word.end\n      \n      if (gap > 0.9 || currentSegment.length >= 50)\n      {\n        segments.push({\n          text: segmentText.trim(),\n          start: segmentStart,\n          end: word.end,\n          words: currentSegment,\n          language: detectedLanguage\n        })\n        \n        currentSegment = []\n        segmentText = ''\n      }\n    }\n  }\n  \n  if (currentSegment.length > 0)\n  {\n    segments.push({\n      text: segmentText.trim(),\n      start: segmentStart,\n      end: currentSegment[currentSegment.length - 1].end,\n      words: currentSegment,\n      language: detectedLanguage\n    })\n  }\n  \n  console.log(`Transcription complete. Language: ${detectedLanguage}, Segments: ${segments.length}`)\n  \n  return segments\n}\n\nexport interface ScoreResult {\n  category: string\n  tags: string[]\n  scores: {\n    hook_strength: number\n    retention_likelihood: number\n    clarity: number\n    shareability: number\n    overall: number\n  }\n  rationale: string\n}\n\nexport async function scoreClip(title: string, hook: string, transcript: string): Promise<ScoreResult> {\n  return withRetries(async () => {\n    const response = await openai.chat.completions.create({\n      model: 'gpt-4o',\n      messages: [\n        {\n          role: 'system',\n          content: 'You are an expert at scoring short-form video clips for TikTok, Instagram Reels, and YouTube Shorts viral potential.'\n        },\n        {\n          role: 'user',\n          content: `Analyze this short video clip for viral potential on TikTok/Reels/Shorts.\n\nCRITICAL HOOK CRITERIA (first 1.5-2.0 seconds):\n- Must grab attention immediately with question, bold claim, or intrigue\n- Avoid slow cold opens - needs energy from frame 1\n- Strong hooks: \"How to...\", \"X vs Y\", questions, shocking facts, controversy, numbers\n\nRETENTION SIGNALS:\n- Fast pacing, low pause density, rising energy\n- Clear Q→A arc or story structure\n- Visual variety without being chaotic (2-4 scene changes ideal)\n- Payoff delivered by end, no trailing off\n\nTIKTOK-SPECIFIC:\n- First 2 seconds determine everything\n- Must work with sound OFF (assume subtitles carry meaning)\n- Clarity over complexity\n- Shareability: meme-able, relatable, or teaches something\n\nSCORING RUBRIC:\n- hook_strength (0-10): How compelling are the first 2 seconds for a cold audience?\n- retention_likelihood (0-10): Will viewers watch to the end? Pacing, payoff, engagement?\n- clarity (0-10): Is the message crystal clear? Minimal filler, coherent flow?\n- shareability (0-10): Would someone share this or save it? Relatable, useful, or entertaining?\n- overall (0-100): Weighted viral potential score\n\nReturn JSON with:\n{\n  \"category\": \"[Education|Motivation|Humor|Commentary|Tech|Lifestyle|News|Finance|Health|Sports|Gaming|Other]\",\n  \"tags\": [\"tag1\", \"tag2\", \"tag3\"],\n  \"scores\": {\n    \"hook_strength\": <0-10>,\n    \"retention_likelihood\": <0-10>,\n    \"clarity\": <0-10>,\n    \"shareability\": <0-10>,\n    \"overall\": <0-100>\n  },\n  \"rationale\": \"<one sentence explaining overall score>\"\n}\n\nINPUT:\nTitle: ${title}\nHook (first 2-3s): ${hook}\nFull transcript: ${transcript}\n\nJSON only, no markdown.`\n        }\n      ],\n      response_format: { type: 'json_object' },\n      temperature: 0.7\n    })\n    \n    const content = response.choices[0].message.content || '{}'\n    return JSON.parse(content) as ScoreResult\n  })\n}\n","size_bytes":13417},"src/services/ffmpeg.ts":{"content":"import ffmpegStatic from 'ffmpeg-static'\nimport ffprobeStatic from 'ffprobe-static'\nimport { spawn } from 'child_process'\nimport { writeFileSync } from 'fs'\nimport * as fs from 'fs/promises'\n\nconst ffmpegPath = ffmpegStatic\nconst ffprobePath = ffprobeStatic.path\n\ninterface Probe {\n  width: number\n  height: number\n  fps: number\n}\n\nfunction run(bin: string, args: string[]): Promise<{ stdout: string, stderr: string }> {\n  return new Promise((resolve, reject) => {\n    const p = spawn(bin, args, { stdio: ['ignore', 'pipe', 'pipe'] })\n    let out = ''\n    let err = ''\n    p.stdout.on('data', d => out += d.toString())\n    p.stderr.on('data', d => err += d.toString())\n    p.on('close', code => {\n      if (code === 0)\n      {\n        resolve({ stdout: out, stderr: err })\n      }\n      else\n      {\n        reject(new Error(err || out))\n      }\n    })\n  })\n}\n\nexport async function probeVideo(file: string): Promise<Probe> {\n  const args = [\n    '-v', 'error',\n    '-select_streams', 'v:0',\n    '-show_entries', 'stream=width,height,avg_frame_rate',\n    '-of', 'json',\n    file\n  ]\n  const { stdout } = await run(ffprobePath, args)\n  const j = JSON.parse(stdout)\n  const s = j.streams[0]\n  const fpsParts = String(s.avg_frame_rate || '0/1').split('/')\n  const fps = Number(fpsParts[1] === '0' ? 0 : Number(fpsParts[0]) / Number(fpsParts[1]))\n  return { width: Number(s.width), height: Number(s.height), fps }\n}\n\nfunction even(n: number): number {\n  if (n % 2 === 0)\n  {\n    return n\n  }\n  return n - 1\n}\n\nfunction escapeDrawtext(text: string): string {\n  return text\n    .replace(/\\\\/g, '\\\\\\\\')\n    .replace(/'/g, \"\\\\'\")\n    .replace(/:/g, '\\\\:')\n    .replace(/\\[/g, '\\\\[')\n    .replace(/\\]/g, '\\\\]')\n}\n\nfunction chooseTargetSize(srcW: number, srcH: number): { w: number, h: number } {\n  let h = srcH\n  if (h > 1920)\n  {\n    h = 1920\n  }\n  const w = even(Math.round(h * 9 / 16))\n  return { w, h: even(h) }\n}\n\nfunction buildFilters(targetW: number, targetH: number): string {\n  const scaleW = \"'if(gt(iw/ih,0.5625),-2,\" + targetW + \")'\"\n  const scaleH = \"'if(gt(iw/ih,0.5625),\" + targetH + \",-2)'\"\n  const chain = [\n    'scale=' + scaleW + ':' + scaleH,\n    'crop=' + targetW + ':' + targetH + ':(in_w-out_w)/2:(in_h-out_h)/2',\n    'format=yuv420p'\n  ]\n  return chain.join(',')\n}\n\nexport async function renderClip(input: string, startSec: number, endSec: number, srtPath: string | null, outFile: string): Promise<void> {\n  const p = await probeVideo(input)\n  const tgt = chooseTargetSize(p.width, p.height)\n  const filters = buildFilters(tgt.w, tgt.h)\n  const vf = srtPath && srtPath.length > 0 ? filters + ',subtitles=\\'' + srtPath.replace(/'/g, '\\\\\\'') + '\\'' : filters\n  const dur = Math.max(0, endSec - startSec)\n  const args = [\n    '-y',\n    '-ss', String(startSec),\n    '-t', String(dur),\n    '-i', input,\n    '-vf', vf,\n    '-c:v', 'libx264',\n    '-profile:v', 'high',\n    '-preset', 'slow',\n    '-crf', '16',\n    '-pix_fmt', 'yuv420p',\n    '-c:a', 'aac',\n    '-b:a', '192k',\n    '-movflags', '+faststart',\n    outFile\n  ]\n  await run(ffmpegPath!, args)\n  await fs.stat(outFile)\n}\n\nexport async function probeBitrate(file: string): Promise<{ size: number, seconds: number, kbps: number }> {\n  const { stdout } = await run(ffprobePath as string, [\n    '-v', 'error',\n    '-show_entries', 'format=duration,size',\n    '-of', 'json',\n    file\n  ])\n  const j = JSON.parse(stdout)\n  const size = Number(j.format.size || 0)\n  const seconds = Number(j.format.duration || 0)\n  const kbps = seconds > 0 ? (size * 8) / seconds / 1000 : 0\n  return { size, seconds, kbps }\n}\n\nexport function getFileSizeBytes(path: string): number {\n  const stat = require('fs').statSync(path)\n  return stat.size\n}\n\nexport async function getDurationSeconds(inputPath: string): Promise<number> {\n  const { stdout } = await run(ffprobePath as string, [\n    '-v', 'error',\n    '-show_entries', 'format=duration',\n    '-of', 'json',\n    inputPath\n  ])\n  const j = JSON.parse(stdout)\n  return Number(j.format.duration || 0)\n}\n\nexport interface SceneChange {\n  timeSec: number\n}\n\nexport async function detectScenes(inputPath: string, threshold = 0.3): Promise<SceneChange[]> {\n  const args = [\n    '-i', inputPath,\n    '-vf', `select='gt(scene,${threshold})',showinfo`,\n    '-f', 'null',\n    '-'\n  ]\n  const { stderr } = await run(ffmpegPath!, args)\n  const lines = stderr.split('\\n')\n  const changes: SceneChange[] = []\n  for (const line of lines)\n  {\n    const match = line.match(/pts_time:([\\d.]+)/)\n    if (match)\n    {\n      changes.push({ timeSec: parseFloat(match[1]) })\n    }\n  }\n  return changes\n}\n\nexport async function extractAudio(inputPath: string, outputPath: string): Promise<void> {\n  await run(ffmpegPath!, [\n    '-y',\n    '-i', inputPath,\n    '-vn',\n    '-acodec', 'copy',\n    outputPath\n  ])\n}\n\nexport async function compressAudioForTranscription(inputPath: string, outputPath: string): Promise<void> {\n  await run(ffmpegPath!, [\n    '-y',\n    '-i', inputPath,\n    '-ar', '16000',\n    '-ac', '1',\n    '-c:a', 'libmp3lame',\n    '-b:a', '64k',\n    outputPath\n  ])\n}\n\nexport async function extractThumbnail(videoPath: string, outputPath: string, timeSec: number): Promise<void> {\n  await run(ffmpegPath!, [\n    '-y',\n    '-ss', String(timeSec),\n    '-i', videoPath,\n    '-vframes', '1',\n    '-q:v', '2',\n    outputPath\n  ])\n}\n\nexport function createSrtFile(words: Array<{ word: string; start: number; end: number }>, outputPath: string): void {\n  let srtContent = ''\n  \n  for (let i = 0; i < words.length; i++)\n  {\n    const word = words[i]\n    const startTime = formatSrtTime(word.start)\n    const endTime = formatSrtTime(word.end)\n    \n    srtContent += `${i + 1}\\n`\n    srtContent += `${startTime} --> ${endTime}\\n`\n    srtContent += `${word.word}\\n\\n`\n  }\n  \n  writeFileSync(outputPath, srtContent)\n}\n\nfunction formatSrtTime(seconds: number): string {\n  const hours = Math.floor(seconds / 3600)\n  const minutes = Math.floor((seconds % 3600) / 60)\n  const secs = Math.floor(seconds % 60)\n  const ms = Math.floor((seconds % 1) * 1000)\n  \n  return `${pad(hours, 2)}:${pad(minutes, 2)}:${pad(secs, 2)},${pad(ms, 3)}`\n}\n\nfunction pad(num: number, size: number): string {\n  let s = num.toString()\n  while (s.length < size)\n  {\n    s = '0' + s\n  }\n  return s\n}\n\ninterface RenderVerticalClipOptions {\n  inputPath: string\n  outputPath: string\n  startTime: number\n  duration: number\n  srtPath: string\n  hookText: string\n}\n\nexport async function renderVerticalClip(options: RenderVerticalClipOptions): Promise<void> {\n  const p = await probeVideo(options.inputPath)\n  const tgt = chooseTargetSize(p.width, p.height)\n  const filters = buildFilters(tgt.w, tgt.h)\n  \n  let vf = filters\n  \n  if (options.srtPath && options.srtPath.length > 0)\n  {\n    vf = vf + ',subtitles=\\'' + options.srtPath.replace(/'/g, '\\\\\\'') + '\\''\n  }\n  \n  if (options.hookText && options.hookText.length > 0)\n  {\n    const hookEscaped = escapeDrawtext(options.hookText)\n    const hookFilter = 'drawtext=text=\\'' + hookEscaped + '\\':fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf:fontsize=52:fontcolor=white:borderw=4:bordercolor=black:x=(w-text_w)/2:y=120'\n    vf = vf + ',' + hookFilter\n  }\n  \n  const dur = Math.max(0, options.duration)\n  const args = [\n    '-y',\n    '-ss', String(options.startTime),\n    '-t', String(dur),\n    '-i', options.inputPath,\n    '-vf', vf,\n    '-c:v', 'libx264',\n    '-profile:v', 'high',\n    '-preset', 'slow',\n    '-crf', '16',\n    '-pix_fmt', 'yuv420p',\n    '-c:a', 'aac',\n    '-b:a', '192k',\n    '-movflags', '+faststart',\n    options.outputPath\n  ]\n  await run(ffmpegPath!, args)\n  await fs.stat(options.outputPath)\n}\n\ninterface RenderSmartFramedClipOptions {\n  inputPath: string\n  outputPath: string\n  startTime: number\n  duration: number\n  srtPath: string\n  hookText: string\n  cropMapExprX: string\n  cropMapExprY: string\n  cropW: number\n  cropH: number\n}\n\nexport async function renderSmartFramedClip(options: RenderSmartFramedClipOptions): Promise<void> {\n  const cropFilter = `crop=${options.cropW}:${options.cropH}:'${options.cropMapExprX}':'${options.cropMapExprY}'`\n  let vf = cropFilter + ',scale=1080:1920,format=yuv420p'\n  \n  if (options.srtPath && options.srtPath.length > 0)\n  {\n    vf = vf + ',subtitles=\\'' + options.srtPath.replace(/'/g, '\\\\\\'') + '\\''\n  }\n  \n  if (options.hookText && options.hookText.length > 0)\n  {\n    const hookEscaped = escapeDrawtext(options.hookText)\n    const hookFilter = 'drawtext=text=\\'' + hookEscaped + '\\':fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf:fontsize=52:fontcolor=white:borderw=4:bordercolor=black:x=(w-text_w)/2:y=120'\n    vf = vf + ',' + hookFilter\n  }\n  \n  const dur = Math.max(0, options.duration)\n  const args = [\n    '-y',\n    '-ss', String(options.startTime),\n    '-t', String(dur),\n    '-i', options.inputPath,\n    '-vf', vf,\n    '-c:v', 'libx264',\n    '-profile:v', 'high',\n    '-preset', 'slow',\n    '-crf', '16',\n    '-pix_fmt', 'yuv420p',\n    '-c:a', 'aac',\n    '-b:a', '192k',\n    '-movflags', '+faststart',\n    options.outputPath\n  ]\n  await run(ffmpegPath!, args)\n  await fs.stat(options.outputPath)\n}\n","size_bytes":9094},"prisma/migrations/migration_lock.toml":{"content":"# Please do not edit this file manually\n# It should be added in your version-control system (i.e. Git)\nprovider = \"postgresql\"","size_bytes":126},"app/api/auth/status/route.ts":{"content":"import { NextResponse } from 'next/server'\nimport { getSession } from '@/src/lib/session'\nimport { checkYouTubeConnection } from '@/src/lib/youtube-client'\n\nexport async function GET() {\n  try {\n    const session = await getSession()\n    const youtubeConnected = await checkYouTubeConnection()\n    \n    return NextResponse.json({\n      isAuthenticated: session.isAuthenticated || false,\n      youtubeConnected,\n      email: session.email || null\n    })\n  }\n  catch (error) {\n    return NextResponse.json({\n      isAuthenticated: false,\n      youtubeConnected: false,\n      email: null\n    })\n  }\n}\n","size_bytes":598},"types/ffprobe-static.d.ts":{"content":"declare module 'ffprobe-static' {\n  const ffprobeStatic: { path: string }\n  export default ffprobeStatic\n}\n","size_bytes":107},"app/api/auth/google/callback/route.ts":{"content":"import { NextRequest, NextResponse } from 'next/server'\nimport { OAuth2Client } from 'google-auth-library'\nimport { prisma } from '@/src/lib/prisma'\nimport { getSession } from '@/src/lib/session'\nimport { encrypt } from '@/src/lib/encryption'\n\nconst getOAuthClient = () => {\n  const clientId = process.env.GOOGLE_CLIENT_ID\n  const clientSecret = process.env.GOOGLE_CLIENT_SECRET\n  \n  let redirectUri = process.env.GOOGLE_REDIRECT_URI\n  \n  if (!redirectUri)\n  {\n    const replitDomain = process.env.REPLIT_DOMAINS?.split(',')[0]\n    \n    if (replitDomain)\n    {\n      redirectUri = `https://${replitDomain}/api/auth/google/callback`\n    }\n    else\n    {\n      redirectUri = 'http://localhost:5000/api/auth/google/callback'\n    }\n  }\n  \n  if (!clientId || !clientSecret)\n  {\n    throw new Error('Google OAuth credentials not configured')\n  }\n  \n  return new OAuth2Client(clientId, clientSecret, redirectUri)\n}\n\nexport async function GET(request: NextRequest) {\n  try {\n    const searchParams = request.nextUrl.searchParams\n    const code = searchParams.get('code')\n    const error = searchParams.get('error')\n    \n    if (error)\n    {\n      return NextResponse.redirect(new URL(`/login?error=${error}`, request.url))\n    }\n    \n    if (!code)\n    {\n      return NextResponse.redirect(new URL('/login?error=no_code', request.url))\n    }\n    \n    const oauth2Client = getOAuthClient()\n    const { tokens } = await oauth2Client.getToken(code)\n    \n    if (!tokens.access_token)\n    {\n      return NextResponse.redirect(new URL('/login?error=no_token', request.url))\n    }\n    \n    oauth2Client.setCredentials(tokens)\n    \n    const oauth2 = await oauth2Client.request({\n      url: 'https://www.googleapis.com/oauth2/v2/userinfo'\n    })\n    \n    const userInfo = oauth2.data as any\n    \n    if (!userInfo.email || !userInfo.id)\n    {\n      return NextResponse.redirect(new URL('/login?error=no_user_info', request.url))\n    }\n    \n    const encryptedAccessToken = tokens.access_token ? encrypt(tokens.access_token) : null\n    const encryptedRefreshToken = tokens.refresh_token ? encrypt(tokens.refresh_token) : null\n    const expiresAt = tokens.expiry_date ? new Date(tokens.expiry_date) : null\n    \n    let user = await prisma.user.findUnique({\n      where: { googleAccountId: userInfo.id }\n    })\n    \n    if (user)\n    {\n      user = await prisma.user.update({\n        where: { id: user.id },\n        data: {\n          email: userInfo.email,\n          googleAccessToken: encryptedAccessToken,\n          googleRefreshToken: encryptedRefreshToken,\n          googleTokenExpiresAt: expiresAt\n        }\n      })\n    }\n    else\n    {\n      user = await prisma.user.create({\n        data: {\n          email: userInfo.email,\n          googleAccountId: userInfo.id,\n          googleAccessToken: encryptedAccessToken,\n          googleRefreshToken: encryptedRefreshToken,\n          googleTokenExpiresAt: expiresAt\n        }\n      })\n    }\n    \n    const session = await getSession()\n    session.isAuthenticated = true\n    session.userId = user.id\n    session.email = user.email\n    await session.save()\n    \n    const replitDomain = process.env.REPLIT_DOMAINS?.split(',')[0]\n    const baseUrl = replitDomain ? `https://${replitDomain}` : request.url\n    \n    return NextResponse.redirect(new URL('/', baseUrl))\n  }\n  catch (error: any) {\n    console.error('Error in Google OAuth callback:', error)\n    \n    const replitDomain = process.env.REPLIT_DOMAINS?.split(',')[0]\n    const baseUrl = replitDomain ? `https://${replitDomain}` : request.url\n    \n    return NextResponse.redirect(new URL('/login?error=callback_failed', baseUrl))\n  }\n}\n","size_bytes":3625},"src/lib/prisma.ts":{"content":"import { PrismaClient } from '@prisma/client'\n\nconst globalForPrisma = globalThis as unknown as {\n  prisma: PrismaClient | undefined\n}\n\nexport const prisma = globalForPrisma.prisma ?? new PrismaClient()\n\nif (process.env.NODE_ENV !== 'production') {\n  globalForPrisma.prisma = prisma\n}\n","size_bytes":285},"app/setup-cookies/page.tsx":{"content":"'use client'\n\nimport { useState, useEffect } from 'react'\nimport { useRouter } from 'next/navigation'\n\nexport default function SetupCookiesPage() {\n  const [loading, setLoading] = useState(false)\n  const [error, setError] = useState('')\n  const [success, setSuccess] = useState(false)\n  const [cookiesText, setCookiesText] = useState('')\n  const [uploadMethod, setUploadMethod] = useState<'paste' | 'file'>('paste')\n  const router = useRouter()\n\n  useEffect(() => {\n    checkAuth()\n  }, [])\n\n  async function checkAuth() {\n    try {\n      const res = await fetch('/api/auth/status')\n      const data = await res.json()\n      \n      if (!data.isAuthenticated)\n      {\n        router.push('/login')\n        return\n      }\n    }\n    catch (err) {\n      console.error('Failed to check auth:', err)\n    }\n  }\n\n  async function handleLogout() {\n    try {\n      await fetch('/api/auth/logout', { method: 'POST' })\n      router.push('/login')\n    }\n    catch (err) {\n      console.error('Failed to logout:', err)\n    }\n  }\n\n  async function handleSubmit(e: React.FormEvent) {\n    e.preventDefault()\n    setLoading(true)\n    setError('')\n    setSuccess(false)\n    \n    try {\n      const res = await fetch('/api/youtube/cookies', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({ cookies: cookiesText })\n      })\n      \n      const data = await res.json()\n      \n      if (!res.ok)\n      {\n        throw new Error(data.error || 'Failed to save cookies')\n      }\n      \n      setSuccess(true)\n      \n      setTimeout(() => {\n        router.push('/')\n      }, 2000)\n    }\n    catch (err: any) {\n      setError(err.message || 'Failed to upload cookies')\n    }\n    finally {\n      setLoading(false)\n    }\n  }\n\n  async function handleFileUpload(e: React.ChangeEvent<HTMLInputElement>) {\n    const file = e.target.files?.[0]\n    \n    if (!file)\n    {\n      return\n    }\n    \n    setLoading(true)\n    setError('')\n    setSuccess(false)\n    \n    try {\n      const formData = new FormData()\n      formData.append('file', file)\n      \n      const res = await fetch('/api/youtube/cookies', {\n        method: 'POST',\n        body: formData\n      })\n      \n      const data = await res.json()\n      \n      if (!res.ok)\n      {\n        throw new Error(data.error || 'Failed to upload cookies')\n      }\n      \n      setSuccess(true)\n      \n      setTimeout(() => {\n        router.push('/')\n      }, 2000)\n    }\n    catch (err: any) {\n      setError(err.message || 'Failed to upload cookies')\n    }\n    finally {\n      setLoading(false)\n    }\n  }\n\n  return (\n    <div className=\"min-h-screen bg-gray-900 text-white p-4\">\n      <div className=\"max-w-3xl mx-auto pt-12\">\n        <div className=\"bg-gray-800 rounded-lg shadow-xl p-8\">\n          <h1 className=\"text-3xl font-bold mb-2\">YouTube Cookies Setup</h1>\n          <p className=\"text-gray-400 mb-8\">\n            To download YouTube videos, we need your YouTube cookies. This allows the app to access videos as if you were signed in.\n          </p>\n          \n          {error && (\n            <div className=\"mb-6 p-4 bg-red-900/50 border border-red-700 rounded-lg\">\n              <p className=\"text-red-200 text-sm mb-2\">{error}</p>\n              {\n                error.includes('sign in again') && (\n                  <button\n                    onClick={handleLogout}\n                    className=\"mt-2 px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded text-sm\"\n                  >\n                    Sign in again\n                  </button>\n                )\n              }\n            </div>\n          )}\n          \n          {success && (\n            <div className=\"mb-6 p-4 bg-green-900/50 border border-green-700 rounded-lg\">\n              <p className=\"text-green-200 text-sm\">Cookies uploaded successfully! Redirecting...</p>\n            </div>\n          )}\n          \n          <div className=\"mb-6\">\n            <div className=\"flex gap-4 mb-6\">\n              <button\n                onClick={() => setUploadMethod('paste')}\n                className={`flex-1 py-2 px-4 rounded-lg transition-colors ${uploadMethod === 'paste' ? 'bg-blue-600' : 'bg-gray-700 hover:bg-gray-600'}`}\n              >\n                Paste Cookies\n              </button>\n              <button\n                onClick={() => setUploadMethod('file')}\n                className={`flex-1 py-2 px-4 rounded-lg transition-colors ${uploadMethod === 'file' ? 'bg-blue-600' : 'bg-gray-700 hover:bg-gray-600'}`}\n              >\n                Upload File\n              </button>\n            </div>\n            \n            {uploadMethod === 'paste' ? (\n              <form onSubmit={handleSubmit}>\n                <textarea\n                  value={cookiesText}\n                  onChange={(e) => setCookiesText(e.target.value)}\n                  placeholder=\"Paste your YouTube cookies in Netscape format here...\"\n                  className=\"w-full h-64 bg-gray-900 text-white border border-gray-700 rounded-lg p-4 font-mono text-sm\"\n                  required\n                />\n                <button\n                  type=\"submit\"\n                  disabled={loading || !cookiesText.trim()}\n                  className=\"mt-4 w-full bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 disabled:cursor-not-allowed text-white font-semibold py-3 px-4 rounded-lg transition-colors\"\n                >\n                  {loading ? 'Uploading...' : 'Save Cookies'}\n                </button>\n              </form>\n            ) : (\n              <div className=\"border-2 border-dashed border-gray-700 rounded-lg p-8 text-center\">\n                <input\n                  type=\"file\"\n                  accept=\".txt\"\n                  onChange={handleFileUpload}\n                  className=\"hidden\"\n                  id=\"cookie-file\"\n                  disabled={loading}\n                />\n                <label\n                  htmlFor=\"cookie-file\"\n                  className=\"cursor-pointer inline-block bg-blue-600 hover:bg-blue-700 text-white font-semibold py-3 px-6 rounded-lg transition-colors\"\n                >\n                  {loading ? 'Uploading...' : 'Choose cookies.txt File'}\n                </label>\n                <p className=\"text-gray-400 text-sm mt-4\">\n                  Select your cookies.txt file exported from your browser\n                </p>\n              </div>\n            )}\n          </div>\n          \n          <div className=\"bg-gray-900 rounded-lg p-6 space-y-4\">\n            <h2 className=\"font-semibold text-lg\">How to export YouTube cookies:</h2>\n            \n            <div className=\"space-y-3 text-sm text-gray-300\">\n              <div>\n                <h3 className=\"font-semibold text-white mb-1\">Using Browser Extension:</h3>\n                <ol className=\"list-decimal list-inside space-y-1 ml-2\">\n                  <li>Install a cookie export extension for your browser</li>\n                  <li>Go to youtube.com and sign in</li>\n                  <li>Export cookies in Netscape format</li>\n                  <li>Paste or upload the cookies.txt file here</li>\n                </ol>\n              </div>\n              \n              <div className=\"pt-3 border-t border-gray-700\">\n                <h3 className=\"font-semibold text-white mb-1\">Required cookies:</h3>\n                <p className=\"text-gray-400\">\n                  Your cookies must include: <span className=\"font-mono text-blue-400\">SAPISID</span>, <span className=\"font-mono text-blue-400\">HSID</span>, and <span className=\"font-mono text-blue-400\">SSID</span>\n                </p>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  )\n}\n","size_bytes":7696},"app/layout.tsx":{"content":"import type { Metadata } from 'next'\nimport { Inter } from 'next/font/google'\nimport './globals.css'\n\nconst inter = Inter({ subsets: ['latin'] })\n\nexport const metadata: Metadata = {\n  title: 'YT Shortsmith',\n  description: 'AI-powered short-form video clip generator',\n}\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={inter.className}>{children}</body>\n    </html>\n  )\n}\n","size_bytes":468},"src/lib/youtube-client.ts":{"content":"import { google } from 'googleapis'\n\nlet connectionSettings: any\n\nasync function getAccessToken() {\n  if (connectionSettings && connectionSettings.settings.expires_at && new Date(connectionSettings.settings.expires_at).getTime() > Date.now())\n  {\n    return connectionSettings.settings.access_token\n  }\n  \n  const hostname = process.env.REPLIT_CONNECTORS_HOSTNAME\n  const xReplitToken = process.env.REPL_IDENTITY \n    ? 'repl ' + process.env.REPL_IDENTITY \n    : process.env.WEB_REPL_RENEWAL \n    ? 'depl ' + process.env.WEB_REPL_RENEWAL \n    : null\n\n  if (!xReplitToken)\n  {\n    throw new Error('X_REPLIT_TOKEN not found for repl/depl')\n  }\n\n  connectionSettings = await fetch(\n    'https://' + hostname + '/api/v2/connection?include_secrets=true&connector_names=youtube',\n    {\n      headers: {\n        'Accept': 'application/json',\n        'X_REPLIT_TOKEN': xReplitToken\n      }\n    }\n  ).then(res => res.json()).then(data => data.items?.[0])\n\n  const accessToken = connectionSettings?.settings?.access_token || connectionSettings.settings?.oauth?.credentials?.access_token\n\n  if (!connectionSettings || !accessToken)\n  {\n    throw new Error('YouTube not connected')\n  }\n  return accessToken\n}\n\nexport async function getYouTubeClient() {\n  const accessToken = await getAccessToken()\n  return google.youtube({ version: 'v3', auth: accessToken })\n}\n\nexport async function checkYouTubeConnection(): Promise<boolean> {\n  try {\n    await getAccessToken()\n    return true\n  }\n  catch {\n    return false\n  }\n}\n","size_bytes":1506},"app/api/videos/[id]/route.ts":{"content":"import { NextRequest, NextResponse } from 'next/server'\nimport { prisma } from '@/src/lib/prisma'\nimport { getSignedUrlForKey, getS3Url } from '@/src/services/s3'\nimport { requireAuth } from '@/src/lib/session'\n\nasync function getUrlForKey(key: string): Promise<string> {\n  try {\n    return await getSignedUrlForKey(key, 7200)\n  }\n  catch (error: any) {\n    if (error.name === 'CredentialsProviderError')\n    {\n      console.warn('S3 credentials not configured, using direct URLs')\n    }\n    else\n    {\n      console.warn('Failed to generate signed URL, falling back to direct URL:', error)\n    }\n    return getS3Url(key)\n  }\n}\n\nexport async function GET(\n  request: NextRequest,\n  { params }: { params: { id: string } }\n) {\n  try {\n    await requireAuth()\n    \n    const video = await prisma.video.findUnique({\n      where: { id: params.id },\n      include: {\n        clips: {\n          orderBy: { scoreOverall: 'desc' }\n        }\n      }\n    })\n    \n    if (!video)\n    {\n      return NextResponse.json(\n        { error: 'Video not found' },\n        { status: 404 }\n      )\n    }\n    \n    const clipsWithUrls = await Promise.all(\n      video.clips.map(async (clip) => ({\n        ...clip,\n        videoUrl: await getUrlForKey(clip.s3VideoKey),\n        thumbUrl: await getUrlForKey(clip.s3ThumbKey),\n        srtUrl: await getUrlForKey(clip.s3SrtKey)\n      }))\n    )\n    \n    return NextResponse.json({\n      ...video,\n      clips: clipsWithUrls\n    })\n  }\n  catch (error: any) {\n    console.error('Error fetching video:', error)\n    \n    if (error.message === 'Authentication required')\n    {\n      return NextResponse.json(\n        { error: 'Authentication required' },\n        { status: 401 }\n      )\n    }\n    \n    return NextResponse.json(\n      { error: 'Failed to fetch video' },\n      { status: 500 }\n    )\n  }\n}\n","size_bytes":1820},"tailwind.config.ts":{"content":"import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  content: [\n    './pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config\n","size_bytes":280},"app/api/youtube/cookies/route.ts":{"content":"import { NextRequest, NextResponse } from 'next/server'\nimport { requireAuth } from '@/src/lib/session'\nimport { prisma } from '@/src/lib/prisma'\nimport { encrypt } from '@/src/lib/encryption'\n\nfunction validateCookies(cookiesText: string): boolean {\n  const lines = cookiesText.split('\\n').filter(line => line.trim() && !line.startsWith('#'))\n  \n  if (lines.length === 0)\n  {\n    return false\n  }\n  \n  const requiredCookies = ['SAPISID', 'HSID', 'SSID']\n  const foundCookies = new Set<string>()\n  \n  for (const line of lines)\n  {\n    const parts = line.split('\\t')\n    \n    if (parts.length < 7)\n    {\n      continue\n    }\n    \n    const cookieName = parts[5]\n    \n    if (requiredCookies.includes(cookieName))\n    {\n      foundCookies.add(cookieName)\n    }\n  }\n  \n  return requiredCookies.every(cookie => foundCookies.has(cookie))\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    const session = await requireAuth()\n    \n    if (!session.userId)\n    {\n      return NextResponse.json(\n        { error: 'User ID not found in session' },\n        { status: 401 }\n      )\n    }\n    \n    const contentType = request.headers.get('content-type') || ''\n    let cookiesText: string\n    \n    if (contentType.includes('multipart/form-data'))\n    {\n      const formData = await request.formData()\n      const file = formData.get('file') as File\n      \n      if (!file)\n      {\n        return NextResponse.json(\n          { error: 'No file provided' },\n          { status: 400 }\n        )\n      }\n      \n      cookiesText = await file.text()\n    }\n    else\n    {\n      const body = await request.json()\n      cookiesText = body.cookies\n      \n      if (!cookiesText)\n      {\n        return NextResponse.json(\n          { error: 'No cookies provided' },\n          { status: 400 }\n        )\n      }\n    }\n    \n    if (!validateCookies(cookiesText))\n    {\n      return NextResponse.json(\n        { error: 'Invalid cookies format or missing required cookies (SAPISID, HSID, SSID)' },\n        { status: 400 }\n      )\n    }\n    \n    const user = await prisma.user.findUnique({\n      where: { id: session.userId }\n    })\n    \n    if (!user)\n    {\n      return NextResponse.json(\n        { error: 'User not found. Please sign in again.' },\n        { status: 404 }\n      )\n    }\n    \n    const encryptedCookies = encrypt(cookiesText)\n    \n    await prisma.user.update({\n      where: { id: session.userId },\n      data: {\n        youtubeCookies: encryptedCookies,\n        youtubeCookiesCreatedAt: new Date(),\n        youtubeCookiesLastUsedAt: new Date()\n      }\n    })\n    \n    return NextResponse.json({ success: true })\n  }\n  catch (error: any) {\n    console.error('Error saving cookies:', error)\n    \n    if (error.message === 'Authentication required')\n    {\n      return NextResponse.json(\n        { error: 'Authentication required' },\n        { status: 401 }\n      )\n    }\n    \n    return NextResponse.json(\n      { error: 'Failed to save cookies' },\n      { status: 500 }\n    )\n  }\n}\n","size_bytes":2986},"app/globals.css":{"content":"@tailwind base;\n@tailwind components;\n@tailwind utilities;\n\nbody {\n  @apply bg-gray-900 text-white;\n}\n","size_bytes":102},"app/api/me/connections/route.ts":{"content":"import { NextResponse } from \"next/server\";\nimport { requireAuth } from \"@/src/lib/session\";\nimport { prisma } from \"@/src/lib/prisma\";\n\nexport async function GET() {\n  try {\n    const session = await requireAuth();\n    if (!session.userId) {\n      return NextResponse.json(\n        { error: \"User ID not found in session\" },\n        { status: 401 },\n      );\n    }\n\n    const user = await prisma.user.findUnique({\n      where: { id: session.userId },\n      select: {\n        googleAccountId: true,\n        googleTokenExpiresAt: true,\n        youtubeCookies: true,\n        youtubeCookiesLastUsedAt: true,\n      },\n    });\n    if (!user) {\n      return NextResponse.json({ error: \"User not found\" }, { status: 404 });\n    }\n\n    const tiktok = await prisma.tikTokConnection.findFirst({\n      where: { userId: session.userId },\n      select: { updatedAt: true },\n    });\n\n    return NextResponse.json({\n      hasOAuth: !!user.googleAccountId,\n      oauthExpired: user.googleTokenExpiresAt\n        ? user.googleTokenExpiresAt < new Date()\n        : true,\n      hasCookies: !!user.youtubeCookies,\n      cookiesLastUsedAt: user.youtubeCookiesLastUsedAt,\n      hasTikTok: !!tiktok,\n      tiktokConnectedAt: tiktok?.updatedAt || null,\n    });\n  } catch (error: any) {\n    if (error.message === \"Authentication required\") {\n      return NextResponse.json(\n        { error: \"Authentication required\" },\n        { status: 401 },\n      );\n    }\n    return NextResponse.json(\n      { error: \"Failed to fetch connections\" },\n      { status: 500 },\n    );\n  }\n}\n","size_bytes":1548},"app/videos/[id]/page.tsx":{"content":"\"use client\";\n\nimport { useState, useEffect } from \"react\";\nimport { useParams } from \"next/navigation\";\nimport Link from \"next/link\";\n\ninterface Clip {\n  id: string;\n  startSec: number;\n  endSec: number;\n  durationSec: number;\n  category: string;\n  tags: string[];\n  scoreHook: number;\n  scoreRetention: number;\n  scoreClarity: number;\n  scoreShare: number;\n  scoreOverall: number;\n  rationale: string;\n  videoUrl: string;\n  thumbUrl: string;\n  srtUrl: string;\n}\n\ninterface Video {\n  id: string;\n  title: string;\n  sourceUrl: string;\n  status: string;\n  durationSec: number;\n  clips: Clip[];\n}\n\nexport default function VideoDetail() {\n  const params = useParams();\n  const [video, setVideo] = useState<Video | null>(null);\n  const [loading, setLoading] = useState(true);\n  const [selectedCategory, setSelectedCategory] = useState<string>(\"all\");\n  const [minScore, setMinScore] = useState<number>(0);\n  const [sending, setSending] = useState<Record<string, boolean>>({});\n  const [sent, setSent] = useState<Record<string, boolean>>({});\n  const [error, setError] = useState<string | null>(null);\n\n  useEffect(() => {\n    const idParam = (params as any)?.id;\n    const id = Array.isArray(idParam) ? idParam[0] : idParam;\n    if (id) {\n      fetchVideo(id);\n    }\n  }, [params]);\n\n  async function fetchVideo(id: string) {\n    setError(null);\n    try {\n      const response = await fetch(`/api/videos/${id}`);\n      const data = await response.json();\n      if (response.ok) {\n        setVideo(data);\n      }\n    } catch (e) {\n      setError(\"Error fetching video\");\n    } finally {\n      setLoading(false);\n    }\n  }\n\n  async function sendToTikTok(clipId: string) {\n    setError(null);\n    setSending((prev) => ({ ...prev, [clipId]: true }));\n    try {\n      const response = await fetch(`/api/tiktok/clip/${clipId}/post`, {\n        method: \"POST\",\n        headers: { \"content-type\": \"application/json\" },\n        body: JSON.stringify({ mode: \"draft\" }),\n      });\n      if (response.ok) {\n        setSent((prev) => ({ ...prev, [clipId]: true }));\n      } else {\n        const data = await response.json().catch(() => null);\n        if (data && data.error) {\n          setError(data.error);\n        } else {\n          setError(\"Failed to send to TikTok\");\n        }\n      }\n    } catch (e) {\n      setError(\"Failed to send to TikTok\");\n    } finally {\n      setSending((prev) => ({ ...prev, [clipId]: false }));\n    }\n  }\n\n  if (loading) {\n    return (\n      <div className=\"min-h-screen p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"text-center\">Loading...</div>\n        </div>\n      </div>\n    );\n  }\n\n  if (!video) {\n    return (\n      <div className=\"min-h-screen p-8\">\n        <div className=\"max-w-7xl mx-auto\">\n          <div className=\"text-center\">Video not found</div>\n        </div>\n      </div>\n    );\n  }\n\n  const categories = [\n    \"all\",\n    ...Array.from(new Set(video.clips.map((c) => c.category))),\n  ];\n\n  const filteredClips = video.clips.filter((clip) => {\n    if (selectedCategory !== \"all\" && clip.category !== selectedCategory) {\n      return false;\n    }\n    if (clip.scoreOverall < minScore) {\n      return false;\n    }\n    return true;\n  });\n\n  return (\n    <div className=\"min-h-screen p-8\">\n      <div className=\"max-w-7xl mx-auto\">\n        <Link\n          href=\"/\"\n          className=\"text-blue-400 hover:text-blue-300 mb-4 inline-block\"\n        >\n          ← Back to Videos\n        </Link>\n\n        <div className=\"bg-gray-800 p-6 rounded-lg mb-4\">\n          <h1 className=\"text-3xl font-bold mb-4\">{video.title}</h1>\n          <div className=\"flex gap-4 text-sm text-gray-400\">\n            <span>\n              Status:{\" \"}\n              <span\n                className={`${\n                  video.status === \"completed\"\n                    ? \"text-green-500\"\n                    : video.status === \"processing\"\n                      ? \"text-blue-500\"\n                      : video.status === \"failed\"\n                        ? \"text-red-500\"\n                        : \"text-gray-500\"\n                }`}\n              >\n                {video.status}\n              </span>\n            </span>\n            <span>Duration: {Math.floor(video.durationSec / 60)}m</span>\n            <span>Clips: {video.clips.length}</span>\n          </div>\n        </div>\n\n        {error && (\n          <div className=\"bg-red-900/40 border border-red-700 text-red-200 p-3 rounded mb-6\">\n            {error}\n          </div>\n        )}\n\n        <div className=\"bg-gray-800 p-6 rounded-lg mb-8\">\n          <h2 className=\"text-xl font-semibold mb-4\">Filters</h2>\n          <div className=\"flex gap-4 flex-wrap\">\n            <div>\n              <label className=\"block text-sm mb-2\">Category</label>\n              <select\n                value={selectedCategory}\n                onChange={(e) => setSelectedCategory(e.target.value)}\n                className=\"px-4 py-2 bg-gray-700 rounded border border-gray-600\"\n              >\n                {categories.map((cat) => (\n                  <option key={cat} value={cat}>\n                    {cat === \"all\" ? \"All Categories\" : cat}\n                  </option>\n                ))}\n              </select>\n            </div>\n            <div>\n              <label className=\"block text-sm mb-2\">\n                Min Score: {minScore}\n              </label>\n              <input\n                type=\"range\"\n                min=\"0\"\n                max=\"100\"\n                value={minScore}\n                onChange={(e) => setMinScore(parseInt(e.target.value))}\n                className=\"w-48\"\n              />\n            </div>\n          </div>\n        </div>\n\n        <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6\">\n          {filteredClips.map((clip) => (\n            <div\n              key={clip.id}\n              className=\"bg-gray-800 rounded-lg overflow-hidden\"\n            >\n              <div className=\"relative pb-[177.77%]\">\n                <video\n                  src={clip.videoUrl}\n                  poster={clip.thumbUrl}\n                  controls\n                  className=\"absolute inset-0 w-full h-full object-cover\"\n                />\n              </div>\n              <div className=\"p-4\">\n                <div className=\"flex justify-between items-center mb-2\">\n                  <span className=\"px-2 py-1 bg-blue-600 rounded text-xs\">\n                    {clip.category}\n                  </span>\n                  <span className=\"text-2xl font-bold text-green-400\">\n                    {clip.scoreOverall}\n                  </span>\n                </div>\n                <div className=\"flex flex-wrap gap-1 mb-2\">\n                  {clip.tags.map((tag, i) => (\n                    <span\n                      key={i}\n                      className=\"px-2 py-0.5 bg-gray-700 rounded text-xs\"\n                    >\n                      {tag}\n                    </span>\n                  ))}\n                </div>\n                <div className=\"text-sm text-gray-400 mb-2\">\n                  <div>Hook: {clip.scoreHook}/10</div>\n                  <div>Retention: {clip.scoreRetention}/10</div>\n                  <div>Clarity: {clip.scoreClarity}/10</div>\n                  <div>Shareability: {clip.scoreShare}/10</div>\n                </div>\n                <p className=\"text-sm text-gray-300 mb-3\">{clip.rationale}</p>\n                <div className=\"text-xs text-gray-500 mb-3\">\n                  {Math.floor(clip.startSec)}s - {Math.floor(clip.endSec)}s (\n                  {clip.durationSec}s)\n                </div>\n                <div className=\"flex gap-2\">\n                  <a\n                    href={clip.videoUrl}\n                    target=\"_blank\"\n                    rel=\"noopener noreferrer\"\n                    className=\"flex-1 text-center px-3 py-1 bg-blue-600 hover:bg-blue-700 rounded text-sm\"\n                  >\n                    Video\n                  </a>\n                  <a\n                    href={clip.srtUrl}\n                    target=\"_blank\"\n                    rel=\"noopener noreferrer\"\n                    className=\"flex-1 text-center px-3 py-1 bg-gray-700 hover:bg-gray-600 rounded text-sm\"\n                  >\n                    SRT\n                  </a>\n                </div>\n                <div className=\"mt-3 flex gap-2\">\n                  <button\n                    onClick={() => sendToTikTok(clip.id)}\n                    disabled={!!sending[clip.id] || !!sent[clip.id]}\n                    className={`flex-1 text-center px-3 py-2 rounded text-sm transition ${\n                      sent[clip.id]\n                        ? \"bg-green-700 cursor-default\"\n                        : sending[clip.id]\n                          ? \"bg-gray-700 cursor-wait\"\n                          : \"bg-pink-600 hover:bg-pink-700\"\n                    }`}\n                  >\n                    {sent[clip.id]\n                      ? \"Sent\"\n                      : sending[clip.id]\n                        ? \"Sending…\"\n                        : \"Send to TikTok\"}\n                  </button>\n                </div>\n              </div>\n            </div>\n          ))}\n        </div>\n        {filteredClips.length === 0 && (\n          <div className=\"text-center py-8 text-gray-400\">\n            No clips match the current filters.\n          </div>\n        )}\n      </div>\n    </div>\n  );\n}\n","size_bytes":9379},"src/lib/encryption.ts":{"content":"import { createCipheriv, createDecipheriv, randomBytes, scryptSync } from 'crypto'\n\nconst ALGORITHM = 'aes-256-gcm'\nconst KEY_LENGTH = 32\nconst IV_LENGTH = 16\nconst SALT_LENGTH = 16\nconst TAG_LENGTH = 16\n\nfunction getKey(salt: Buffer): Buffer {\n  const secret = process.env.SESSION_SECRET || 'complex_password_at_least_32_characters_long_for_session_security'\n  return scryptSync(secret, salt, KEY_LENGTH)\n}\n\nexport function encrypt(text: string): string {\n  const salt = randomBytes(SALT_LENGTH)\n  const iv = randomBytes(IV_LENGTH)\n  const key = getKey(salt)\n  \n  const cipher = createCipheriv(ALGORITHM, key, iv)\n  \n  const encrypted = Buffer.concat([\n    cipher.update(text, 'utf8'),\n    cipher.final()\n  ])\n  \n  const tag = cipher.getAuthTag()\n  \n  const result = Buffer.concat([salt, iv, tag, encrypted])\n  return result.toString('base64')\n}\n\nexport function decrypt(encryptedText: string): string {\n  const buffer = Buffer.from(encryptedText, 'base64')\n  \n  const salt = buffer.subarray(0, SALT_LENGTH)\n  const iv = buffer.subarray(SALT_LENGTH, SALT_LENGTH + IV_LENGTH)\n  const tag = buffer.subarray(SALT_LENGTH + IV_LENGTH, SALT_LENGTH + IV_LENGTH + TAG_LENGTH)\n  const encrypted = buffer.subarray(SALT_LENGTH + IV_LENGTH + TAG_LENGTH)\n  \n  const key = getKey(salt)\n  \n  const decipher = createDecipheriv(ALGORITHM, key, iv)\n  decipher.setAuthTag(tag)\n  \n  const decrypted = Buffer.concat([\n    decipher.update(encrypted),\n    decipher.final()\n  ])\n  \n  return decrypted.toString('utf8')\n}\n","size_bytes":1497},"app/api/auth/logout/route.ts":{"content":"import { NextResponse } from 'next/server'\nimport { getSession } from '@/src/lib/session'\n\nexport async function POST() {\n  try {\n    const session = await getSession()\n    session.destroy()\n    \n    return NextResponse.json({ success: true })\n  }\n  catch (error) {\n    return NextResponse.json(\n      { error: 'Failed to logout' },\n      { status: 500 }\n    )\n  }\n}\n","size_bytes":367},"src/services/segmentation.ts":{"content":"import { TranscriptSegment, TranscriptWord } from './openai'\nimport { SceneChange } from './ffmpeg'\nimport { Chapter } from './youtube'\n\nfunction isIntroChapter(title: string, detectedLanguage?: string): boolean {\n  const titleLower = title.toLowerCase().trim()\n  \n  const introKeywords: Record<string, string[]> = {\n    'en': ['intro', 'introduction', 'opening', 'welcome', 'trailer', 'credits'],\n    'es': ['intro', 'introduccion', 'introducción', 'apertura', 'inicio', 'inicio del video', 'inicio del vídeo', 'bienvenida'],\n    'pt': ['intro', 'introducao', 'introduçao', 'introdução', 'apresentacao', 'apresentação', 'abertura', 'boas-vindas'],\n    'fr': ['intro', 'introduction', 'ouverture', 'bienvenue'],\n    'de': ['intro', 'einführung', 'einleitung', 'eröffnung', 'willkommen'],\n    'it': ['intro', 'introduzione', 'apertura', 'benvenuto'],\n    'ja': ['イントロ', '紹介', 'オープニング'],\n    'ko': ['인트로', '소개', '오프닝'],\n    'zh': ['介绍', '简介', '开场'],\n    'ru': ['вступление', 'введение', 'открытие']\n  }\n  \n  let keywordsToCheck = introKeywords['en'] || []\n  \n  if (detectedLanguage && introKeywords[detectedLanguage])\n  {\n    keywordsToCheck = [...introKeywords[detectedLanguage], ...introKeywords['en']]\n  }\n  else {\n    keywordsToCheck = Object.values(introKeywords).flat()\n  }\n  \n  for (const keyword of keywordsToCheck)\n  {\n    if (titleLower.includes(keyword))\n    {\n      return true\n    }\n  }\n  \n  if (titleLower.length < 20 && (titleLower.match(/^(chapter|capítulo|part|parte|section|secção|seção|episode|episódio)\\s*[0-9]+/)))\n  {\n    return false\n  }\n  \n  return false\n}\n\nexport interface Segment {\n  startSec: number\n  endSec: number\n  durationSec: number\n  words: TranscriptWord[]\n  text: string\n  hook: string\n  score: number\n  chapterTitle?: string\n}\n\nfunction hasOverlap(seg1: Segment, seg2: Segment): boolean {\n  return !(seg1.endSec <= seg2.startSec || seg2.endSec <= seg1.startSec)\n}\n\nfunction removeOverlaps(segments: Segment[]): Segment[] {\n  if (segments.length === 0) return []\n  \n  const sorted = [...segments].sort((a, b) => b.score - a.score)\n  const selected: Segment[] = []\n  \n  for (const segment of sorted) {\n    let overlaps = false\n    for (const existing of selected) {\n      if (hasOverlap(segment, existing)) {\n        overlaps = true\n        break\n      }\n    }\n    \n    if (!overlaps) {\n      selected.push(segment)\n    }\n  }\n  \n  return selected.sort((a, b) => a.startSec - b.startSec)\n}\n\nexport function detectSegments(\n  transcript: TranscriptSegment[], \n  sceneChanges: SceneChange[], \n  chapters: Chapter[] = [], \n  videoDuration: number = 0\n): Segment[] {\n  const allWords: TranscriptWord[] = []\n  \n  for (const segment of transcript) {\n    for (const word of segment.words) {\n      allWords.push(word)\n    }\n  }\n  \n  if (allWords.length === 0) {\n    return []\n  }\n  \n  let chaptersToAnalyze: Chapter[] = []\n  const detectedLanguage = transcript[0]?.language\n  \n  if (chapters.length > 0) {\n    const firstChapter = chapters[0]\n    const isIntro = isIntroChapter(firstChapter.title, detectedLanguage)\n    \n    if (isIntro)\n    {\n      console.log(`First chapter \"${firstChapter.title}\" detected as intro, analyzing remaining chapters`)\n      chaptersToAnalyze = chapters.slice(1)\n    }\n    else {\n      console.log(`First chapter \"${firstChapter.title}\" not detected as intro, analyzing all chapters`)\n      chaptersToAnalyze = chapters\n    }\n  } else {\n    const introSkip = parseInt(process.env.INTRO_SKIP_SECONDS || '180', 10)\n    console.log(`No chapters found. Using fallback: skipping first ${introSkip} seconds`)\n    chaptersToAnalyze = [{\n      title: 'Main Content',\n      startSec: introSkip,\n      endSec: videoDuration || Math.max(...allWords.map(w => w.end))\n    }]\n  }\n  \n  if (chaptersToAnalyze.length === 0) {\n    console.log('No chapters to analyze after skipping intro')\n    return []\n  }\n  \n  const allCandidates: Segment[] = []\n  \n  for (const chapter of chaptersToAnalyze) {\n    console.log(`Analyzing chapter: \"${chapter.title}\" (${chapter.startSec}s - ${chapter.endSec}s)`)\n    \n    const chapterWords = allWords.filter(w => \n      w.start >= chapter.startSec && w.start < chapter.endSec\n    )\n    \n    if (chapterWords.length === 0) {\n      console.log(`  No words found in chapter \"${chapter.title}\"`)\n      continue\n    }\n    \n    const pauseBoundaries: number[] = []\n    \n    for (let i = 0; i < chapterWords.length - 1; i++) {\n      const gap = chapterWords[i + 1].start - chapterWords[i].end\n      \n      if (gap >= 0.35 && gap <= 0.9) {\n        pauseBoundaries.push(i + 1)\n      }\n    }\n    \n    const chapterCandidates: Segment[] = []\n    \n    for (let i = 0; i < pauseBoundaries.length; i++) {\n      const startIdx = pauseBoundaries[i]\n      \n      for (let j = i + 1; j < pauseBoundaries.length; j++) {\n        const endIdx = pauseBoundaries[j]\n        const segmentWords = chapterWords.slice(startIdx, endIdx)\n        \n        if (segmentWords.length === 0) continue\n        \n        const startSec = segmentWords[0].start\n        const endSec = segmentWords[segmentWords.length - 1].end\n        const duration = endSec - startSec\n        \n        if (duration >= 20 && duration <= 60) {\n          const speechDuration = segmentWords.reduce((sum, w) => sum + (w.end - w.start), 0)\n          \n          if (speechDuration >= 8) {\n            const text = segmentWords.map(w => w.word).join(' ')\n            const hookWords = segmentWords.filter(w => w.start - startSec < 3)\n            const hook = hookWords.map(w => w.word).join(' ').trim()\n            \n            const wordsPerSec = segmentWords.length / duration\n            const pauseDensity = (duration - speechDuration) / duration\n            const highEnergyWords = segmentWords.filter(w => \n              w.word.length > 6 || /[!?]/.test(w.word)\n            ).length\n            \n            const sceneChangesInSegment = sceneChanges.filter(scene => \n              scene.timeSec >= startSec && scene.timeSec <= endSec\n            ).length\n            \n            const startsNearScene = sceneChanges.some(scene =>\n              Math.abs(scene.timeSec - startSec) <= 1.0\n            )\n            \n            const endsNearScene = sceneChanges.some(scene =>\n              Math.abs(scene.timeSec - endSec) <= 1.0\n            )\n            \n            let sceneBonus = 0\n            \n            if (startsNearScene) sceneBonus += 5\n            if (endsNearScene) sceneBonus += 5\n            if (sceneChangesInSegment > 2) sceneBonus += sceneChangesInSegment * 2\n            \n            const score = wordsPerSec * 10 + pauseDensity * 5 + highEnergyWords + sceneBonus\n            \n            chapterCandidates.push({\n              startSec,\n              endSec,\n              durationSec: duration,\n              words: segmentWords,\n              text,\n              hook: hook || text.substring(0, 50),\n              score,\n              chapterTitle: chapter.title\n            })\n          }\n        }\n      }\n    }\n    \n    const nonOverlappingInChapter = removeOverlaps(chapterCandidates)\n    console.log(`  Found ${nonOverlappingInChapter.length} non-overlapping segments in chapter \"${chapter.title}\"`)\n    allCandidates.push(...nonOverlappingInChapter)\n  }\n  \n  allCandidates.sort((a, b) => b.score - a.score)\n  \n  const preferredCandidates = allCandidates.filter(c => c.durationSec >= 25 && c.durationSec <= 45)\n  \n  if (preferredCandidates.length > 0) {\n    return preferredCandidates.slice(0, 12)\n  }\n  \n  return allCandidates.slice(0, 12)\n}\n","size_bytes":7585},"src/lib/session.ts":{"content":"import { getIronSession } from \"iron-session\";\nimport { cookies } from \"next/headers\";\n\nexport interface SessionData {\n  isAuthenticated: boolean;\n  userId?: string;\n  email?: string;\n}\n\nexport async function getSession() {\n  const sessionCookies = await cookies();\n\n  return getIronSession<SessionData>(sessionCookies, {\n    password:\n      process.env.SESSION_SECRET ||\n      \"complex_password_at_least_32_characters_long_for_session_security\",\n    cookieName: \"yt_shortsmith_session\",\n    cookieOptions: {\n      secure: process.env.NODE_ENV === \"production\",\n      httpOnly: true,\n      sameSite: \"lax\",\n      maxAge: 60 * 60 * 24 * 7,\n      path: \"/\",\n    },\n  });\n}\n\nexport async function requireAuth() {\n  const session = await getSession();\n\n  if (!session.isAuthenticated) {\n    throw new Error(\"Authentication required\");\n  }\n\n  return session;\n}\n\nexport async function getCurrentUserId() {\n  const s = await requireAuth();\n  if (!s.userId) {\n    return \"\";\n  }\n  return s.userId;\n}\n","size_bytes":992},"next.config.js":{"content":"/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  experimental: {\n    serverActions: {\n      bodySizeLimit: '2mb'\n    }\n  },\n  eslint: {\n    ignoreDuringBuilds: true\n  }\n}\n\nmodule.exports = nextConfig\n","size_bytes":215},"replit.md":{"content":"# YT Shortsmith\n\n## Overview\nYT Shortsmith is an AI-powered service that automates the creation of engaging short-form video clips from YouTube videos. It handles downloading, transcribing, intelligently segmenting, and formatting videos into 20-60 second vertical clips optimized for social media platforms like TikTok, Instagram Reels, and YouTube Shorts. The project aims to streamline content repurposing for creators, enabling them to transform long-form content into high-impact social media assets efficiently.\n\n## User Preferences\nPreferred communication style: Simple, everyday language.\n\nCode style constraints:\n- Never add comments to code\n- Always put single if conditions inside brackets with line breaks\n- Focus on clean, self-documenting code\n\n## System Architecture\n\n### Frontend\nThe frontend uses Next.js 14 (App Router), TypeScript, and TailwindCSS for a modern, responsive user interface with server-side rendering. It includes a dashboard and video detail pages.\n\n### Backend\nThe backend, built with Node.js 20 and TypeScript, utilizes a Next.js API layer for REST endpoints and a BullMQ-powered worker process (`src/worker.ts`) for asynchronous video processing.\n\n**Core Processing Pipeline:**\n1.  **Job Creation**: User submits YouTube URL, triggering video record creation and job enqueuing.\n2.  **Video Ingestion**: Downloads video metadata and the video itself via `yt-dlp`.\n3.  **Audio Processing**: Extracts, compresses, and transcribes audio using Whisper API with word-level timestamps.\n4.  **Intelligent Segmentation**: Segments videos into 20-60 second clips (preferring 25-45s) based on voice activity, pauses, and scene changes, with AI scoring to remove overlapping or lower-quality segments.\n5.  **Clip Generation**: Converts selected segments to 9:16 vertical format, applies smart cropping, adds burned-in subtitles, hook text overlay, and generates a thumbnail. Assets are uploaded to S3.\n6.  **Smart Framing (Optional)**: Uses face detection and speaker timelines to generate dynamic crop keyframes for smooth panning.\n7.  **AI Scoring**: GPT-4o scores clips based on a rubric (hook, retention, clarity, shareability), generating categories, tags, and rationale.\n8.  **Data Storage**: Stores clip metadata, scores, S3 keys, and crop maps in the database.\n\n**Data Models (Prisma):**\n-   `User`: Authentication and user-specific data.\n-   `Video`: Source YouTube video metadata.\n-   `Clip`: Generated short video clips and their associated data.\n-   `TikTokConnection`: User TikTok OAuth tokens.\n\n**Core Services:**\n-   **`framingService.ts`**: Manages smart framing, including TensorFlow.js for face detection and keyframe generation.\n-   **`ffmpeg.ts`**: Handles all video/audio processing tasks (rendering, audio extraction, thumbnail generation, scene detection).\n-   **`youtube.ts`**: Manages `yt-dlp` operations for YouTube video interaction (downloading, metadata).\n-   **`segmentation.ts`**: Implements intelligent clip segmentation logic and scoring.\n-   **`openai.ts`**: Integrates OpenAI APIs for Whisper transcription and GPT-4o clip scoring.\n-   **`s3.ts`**: Provides S3 object storage functionalities.\n-   **`queue.ts`**: Configures BullMQ for job orchestration.\n\n### UI/UX Decisions\nThe application uses Next.js with TailwindCSS to provide a modern, dark-themed interface, offering a consistent and visually appealing user experience.\n\n### System Design Choices\n-   **Asynchronous Processing**: Utilizes BullMQ and Redis for robust, scalable background job processing.\n-   **Modular Architecture**: Services are clearly separated (e.g., `ffmpeg`, `youtube`, `openai`) for maintainability.\n-   **Prisma ORM**: Simplifies database interactions and schema management.\n-   **Smart Framing**: Incorporates advanced computer vision and AI for dynamic, engaging video framing.\n\n## External Dependencies\n\n**Database:**\n-   **PostgreSQL**: Primary data store, managed by Prisma ORM.\n\n**Queue System:**\n-   **Redis**: Used by BullMQ for managing asynchronous job queues.\n\n**AI Services:**\n-   **OpenAI Whisper API**: For highly accurate audio transcription.\n-   **GPT-4o**: Utilized for intelligent clip scoring, categorization, and rationale generation.\n\n**Video Processing Libraries:**\n-   **ffmpeg**: The core video and audio manipulation tool, integrated via `fluent-ffmpeg` and `ffmpeg-static`.\n-   **yt-dlp**: For downloading YouTube videos and extracting metadata.\n\n**Object Storage:**\n-   **S3-compatible storage**: Used for storing generated video clips, thumbnails, and SRT files (AWS SDK v3).\n\n**Face Detection & AI Models:**\n-   **@vladmandic/face-api**: For face detection (SSD MobileNet v1) in smart framing.\n-   **@tensorflow/tfjs-node**: TensorFlow backend supporting AI models for face detection.\n\n## Recent Enhancements\n\n### Segmentation V2 System (October 14, 2025)\nComplete rewrite of clip detection with TikTok-optimized algorithms (`src/services/segmentation-v2.ts`):\n\n**Multi-Factor Scoring** (weighted blend):\n- Hook strength: 28% - Detects questions, bold claims, \"How to\", \"X vs Y\", numbers\n- Retention likelihood: 18% - Speech rate, pause density, Q→A arcs, scene changes (2-4 ideal)\n- Clarity: 16% - Filler word ratio, coherent message flow\n- Visual quality: 12% - Scene change density, stable framing\n- Novelty: 10% - Topic freshness (placeholder for embedding distance)\n- Engagement signals: 10% - Audience attention proxies (comment hotspots planned for future)\n- Safety: 6% - Profanity/brand risk detection\n\n**Adaptive Duration Selection**:\n- Short (30s): Standard clips with good hook\n- Mid (45s): High retention (>0.7) + good hook (>0.6)\n- Long (60s): Exceptional hook (>0.8) + exceptional retention (>0.8)\n- Auto-adjusts for clarity: poor clarity (<0.5) caps at 35s\n\n**Hook Detection Patterns**:\n- Questions: \"How\", \"What\", \"Why\", \"Can\", \"Will\", etc.\n- Bold claims: \"This is\", \"The best\", \"Never\", \"Always\", \"Secret\", \"Truth\"\n- Controversy: \"vs.\", \"versus\", \"compared to\"\n- Numbers and statistics\n\n**Speech Dynamics Analysis** (first 5 seconds):\n- Speech rate: words per second\n- Pause density: silence ratio\n- Energy level: caps, punctuation, long words\n\n**Chapter-Bounded Sweeps**:\n- Adaptive step size: max(45s, 10% of chapter length)\n- Windows: 75s candidate zones\n- Smart intro skip with multilingual detection\n\n**Quality Guards**:\n- Minimum 3 words in first 3 seconds\n- Safety score ≥0.5 (profanity filter)\n- Clarity score ≥0.3 (filler word threshold)\n\n**Diversity Filter**:\n- Text similarity threshold: 0.7\n- Prevents near-duplicate clips\n- Jaccard index on word sets\n\n**Explainable Rationale**:\n- Stores top 3 ranking factors per clip\n- Examples: \"strong hook, high retention potential, good visual pacing\"\n\n**New Database Fields**:\n- `Clip.rationaleShort`: Human-readable ranking explanation\n- `Clip.featuresJson`: Full feature vector for analysis\n- `Clip.durationChoice`: \"short30\" | \"mid45\" | \"long60\"\n\n**Enhanced GPT-4o Scoring**:\nUpdated prompt with TikTok-specific criteria: first 2 seconds are critical, must work with sound OFF, clarity over complexity, shareability focus.\n\n### Body-Aware Smart Framing (October 14, 2025)\nEnhanced face detection to estimate full body structure for natural composition:\n- Head height calculation from eyebrow to chin landmarks\n- Shoulder width estimation from jawline corners\n- Torso projection (2.7× head height, configurable via `FRAMING_TORSO_MULTIPLIER`)\n- Centers crop on body centroid (40% down body height) instead of face only\n- Graceful fallback to face-only mode if landmarks unavailable\n- Works with existing 68-point landmarks, no new ML models required\n\n### Universal Language Detection (October 13, 2025)\n- Whisper API automatically detects and transcribes in source language\n- Portuguese videos → Portuguese subtitles, English videos → English subtitles, etc.\n- Detected language stored in transcript metadata for downstream AI processing\n\n### Chapter-Based Intro Skipping (October 13, 2025)\nSmart intro detection using YouTube chapter metadata with 3-tier logic:\n- If chapters exist + first chapter IS intro → skip only that chapter\n- If chapters exist + first chapter is NOT intro → process from start (no skip)\n- If no chapters exist → fallback to 180-second skip\n- Multilingual intro keywords in 10 languages (EN, ES, PT, FR, DE, IT, JA, KO, ZH, RU)","size_bytes":8312},"app/api/videos/[id]/cancel/route.ts":{"content":"import { NextRequest, NextResponse } from 'next/server'\nimport { requireAuth } from '@/src/lib/session'\nimport { prisma } from '@/src/lib/prisma'\nimport { videoQueue } from '@/src/lib/queue'\n\nexport async function POST(\n  request: NextRequest,\n  { params }: { params: { id: string } }\n) {\n  try {\n    const session = await requireAuth()\n    const { id } = params\n    \n    const video = await prisma.video.findUnique({\n      where: { id, userId: session.userId }\n    })\n    \n    if (!video)\n    {\n      return NextResponse.json({ error: 'Video not found' }, { status: 404 })\n    }\n    \n    if (video.status !== 'processing')\n    {\n      return NextResponse.json({ error: 'Video is not processing' }, { status: 400 })\n    }\n    \n    const job = await videoQueue.getJob(id)\n    \n    if (job)\n    {\n      await job.remove()\n    }\n    \n    await prisma.video.update({\n      where: { id },\n      data: { status: 'cancelled' }\n    })\n    \n    return NextResponse.json({ success: true })\n  }\n  catch (error) {\n    console.error('Error cancelling video:', error)\n    return NextResponse.json({ error: 'Failed to cancel video' }, { status: 500 })\n  }\n}\n","size_bytes":1143},"src/services/s3.ts":{"content":"import { S3Client, PutObjectCommand, GetObjectCommand } from '@aws-sdk/client-s3'\nimport { getSignedUrl } from '@aws-sdk/s3-request-presigner'\nimport { readFileSync } from 'fs'\n\nconst s3Client = new S3Client({\n  endpoint: process.env.S3_ENDPOINT,\n  region: process.env.S3_REGION || 'auto',\n  credentials: process.env.S3_ACCESS_KEY_ID && process.env.S3_SECRET_ACCESS_KEY ? {\n    accessKeyId: process.env.S3_ACCESS_KEY_ID,\n    secretAccessKey: process.env.S3_SECRET_ACCESS_KEY\n  } : undefined\n})\n\nconst bucket = process.env.S3_BUCKET!\n\nexport async function uploadFile(key: string, filePath: string, contentType: string): Promise<string> {\n  const fileContent = readFileSync(filePath)\n  \n  await s3Client.send(new PutObjectCommand({\n    Bucket: bucket,\n    Key: key,\n    Body: fileContent,\n    ContentType: contentType,\n    ContentDisposition: 'inline'\n  }))\n  \n  if (process.env.S3_ENDPOINT)\n  {\n    return `${process.env.S3_ENDPOINT}/${bucket}/${key}`\n  }\n  return `https://${bucket}.s3.${process.env.S3_REGION}.amazonaws.com/${key}`\n}\n\nexport async function getSignedUrlForKey(key: string, expiresIn: number = 3600): Promise<string> {\n  const command = new GetObjectCommand({\n    Bucket: bucket,\n    Key: key\n  })\n  \n  return await getSignedUrl(s3Client, command, { expiresIn })\n}\n\nexport async function uploadBuffer(key: string, buffer: Buffer, contentType: string): Promise<string> {\n  await s3Client.send(new PutObjectCommand({\n    Bucket: bucket,\n    Key: key,\n    Body: buffer,\n    ContentType: contentType,\n    ContentDisposition: 'inline'\n  }))\n  \n  if (process.env.S3_ENDPOINT)\n  {\n    return `${process.env.S3_ENDPOINT}/${bucket}/${key}`\n  }\n  return `https://${bucket}.s3.${process.env.S3_REGION}.amazonaws.com/${key}`\n}\n\nexport function getS3Url(key: string): string {\n  if (process.env.S3_ENDPOINT)\n  {\n    return `${process.env.S3_ENDPOINT}/${bucket}/${key}`\n  }\n  return `https://${bucket}.s3.${process.env.S3_REGION}.amazonaws.com/${key}`\n}\n","size_bytes":1957},"app/api/submit/route.ts":{"content":"import { NextRequest, NextResponse } from 'next/server'\nimport { prisma } from '@/src/lib/prisma'\nimport { videoQueue } from '@/src/lib/queue'\nimport { getVideoMetadata } from '@/src/services/youtube'\nimport { requireAuth } from '@/src/lib/session'\n\nfunction sanitizeUrl(url: string): string {\n  const trimmed = url.trim()\n  const urlPattern = /^(https?:\\/\\/)?(www\\.)?(youtube\\.com|youtu\\.be)\\/.+$/i\n  \n  if (!urlPattern.test(trimmed))\n  {\n    throw new Error('Invalid YouTube URL')\n  }\n  \n  return trimmed\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    const session = await requireAuth()\n    \n    if (!session.userId)\n    {\n      return NextResponse.json(\n        { error: 'User ID not found in session' },\n        { status: 401 }\n      )\n    }\n    \n    const user = await prisma.user.findUnique({\n      where: { id: session.userId },\n      select: { youtubeCookies: true }\n    })\n    \n    if (!user || !user.youtubeCookies)\n    {\n      return NextResponse.json(\n        { error: 'YouTube cookies not configured. Please upload your YouTube cookies first.' },\n        { status: 401 }\n      )\n    }\n    \n    const body = await request.json()\n    const { url } = body\n    \n    if (!url)\n    {\n      return NextResponse.json(\n        { error: 'URL is required' },\n        { status: 400 }\n      )\n    }\n    \n    const sanitizedUrl = sanitizeUrl(url)\n    \n    const metadata = await getVideoMetadata(sanitizedUrl, session.userId)\n    \n    const video = await prisma.video.create({\n      data: {\n        userId: session.userId,\n        sourceUrl: sanitizedUrl,\n        title: metadata.title,\n        durationSec: metadata.duration,\n        status: 'queued'\n      }\n    })\n    \n    await videoQueue.add('process', {\n      videoId: video.id,\n      userId: session.userId\n    })\n    \n    return NextResponse.json({\n      videoId: video.id,\n      status: 'queued'\n    })\n  }\n  catch (error: any) {\n    console.error('Error submitting video:', error)\n    \n    if (error.message === 'Authentication required')\n    {\n      return NextResponse.json(\n        { error: 'Authentication required' },\n        { status: 401 }\n      )\n    }\n    \n    if (error.message === 'Invalid YouTube URL')\n    {\n      return NextResponse.json(\n        { error: 'Invalid YouTube URL' },\n        { status: 400 }\n      )\n    }\n    \n    if (error.message.includes('YouTube cookies'))\n    {\n      return NextResponse.json(\n        { error: error.message },\n        { status: 401 }\n      )\n    }\n    \n    return NextResponse.json(\n      { error: 'Failed to submit video' },\n      { status: 500 }\n    )\n  }\n}\n","size_bytes":2590},"src/lib/queue.ts":{"content":"import { Queue, QueueOptions } from 'bullmq'\nimport IORedis from 'ioredis'\n\nconst connection = new IORedis(process.env.REDIS_URL || 'redis://localhost:6379', {\n  maxRetriesPerRequest: null\n})\n\nconst queueOptions: QueueOptions = {\n  connection\n}\n\nexport const videoQueue = new Queue('video.process', queueOptions)\n\nexport { connection }\n","size_bytes":336},"app/page.tsx":{"content":"\"use client\";\n\nimport { useState, useEffect } from \"react\";\nimport Link from \"next/link\";\nimport { useRouter } from \"next/navigation\";\n\ninterface Video {\n  id: string;\n  title: string;\n  sourceUrl: string;\n  status: string;\n  durationSec: number;\n  createdAt: string;\n  _count: {\n    clips: number;\n  };\n}\n\nexport default function Home() {\n  const [url, setUrl] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [videos, setVideos] = useState<Video[]>([]);\n  const [error, setError] = useState(\"\");\n  const [authStatus, setAuthStatus] = useState<any>(null);\n  const [connections, setConnections] = useState<any>(null);\n  const router = useRouter();\n\n  useEffect(() => {\n    checkAuth();\n  }, []);\n\n  async function checkAuth() {\n    try {\n      const res = await fetch(\"/api/auth/status\");\n      const data = await res.json();\n      setAuthStatus(data);\n\n      if (!data.isAuthenticated) {\n        router.push(\"/login\");\n        return;\n      }\n\n      const connectionsRes = await fetch(\"/api/me/connections\");\n      const connectionsData = await connectionsRes.json();\n      setConnections(connectionsData);\n\n      if (!connectionsData.hasCookies) {\n        router.push(\"/setup-cookies\");\n        return;\n      }\n\n      fetchVideos();\n    } catch (err) {\n      console.error(\"Failed to check auth:\", err);\n      router.push(\"/login\");\n    }\n  }\n\n  async function fetchVideos() {\n    try {\n      const response = await fetch(\"/api/videos\");\n      const data = await response.json();\n\n      if (response.ok) {\n        setVideos(data.videos);\n      }\n    } catch (err) {\n      console.error(\"Error fetching videos:\", err);\n    }\n  }\n\n  async function handleSubmit(e: React.FormEvent) {\n    e.preventDefault();\n    setLoading(true);\n    setError(\"\");\n\n    try {\n      const response = await fetch(\"/api/submit\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n        },\n        body: JSON.stringify({ url }),\n      });\n\n      const data = await response.json();\n\n      if (response.ok) {\n        setUrl(\"\");\n        fetchVideos();\n      } else {\n        setError(data.error || \"Failed to submit video\");\n      }\n    } catch (err) {\n      setError(\"Failed to submit video\");\n    } finally {\n      setLoading(false);\n    }\n  }\n\n  async function handleLogout() {\n    try {\n      await fetch(\"/api/auth/logout\", { method: \"POST\" });\n      router.push(\"/login\");\n    } catch (err) {\n      console.error(\"Failed to logout:\", err);\n    }\n  }\n\n  async function handleCancel(videoId: string) {\n    if (!confirm(\"Are you sure you want to cancel this video processing?\")) {\n      return;\n    }\n\n    try {\n      const response = await fetch(`/api/videos/${videoId}/cancel`, {\n        method: \"POST\",\n      });\n\n      if (response.ok) {\n        fetchVideos();\n      } else {\n        const data = await response.json();\n        alert(data.error || \"Failed to cancel video\");\n      }\n    } catch (err) {\n      console.error(\"Failed to cancel video:\", err);\n      alert(\"Failed to cancel video\");\n    }\n  }\n\n  if (!authStatus || !connections) {\n    return (\n      <div className=\"min-h-screen flex items-center justify-center\">\n        <div className=\"text-gray-400\">Loading...</div>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"min-h-screen p-8\">\n      <div className=\"max-w-6xl mx-auto\">\n        <div className=\"flex justify-between items-center mb-8\">\n          <h1 className=\"text-4xl font-bold\">YT Shortsmith</h1>\n          <div className=\"flex items-center gap-4\">\n            <div className=\"flex items-center gap-2\">\n              <div\n                className={`w-2 h-2 rounded-full ${connections.hasCookies ? \"bg-green-500\" : \"bg-red-500\"}`}\n              ></div>\n              <span className=\"text-sm text-gray-400\">\n                {connections.hasCookies ? \"YouTube Connected\" : \"No Cookies\"}\n              </span>\n            </div>\n            <div className=\"flex items-center gap-2\">\n              <div\n                className={`w-2 h-2 rounded-full ${connections.hasTikTok ? \"bg-green-500\" : \"bg-red-500\"}`}\n              ></div>\n              <span className=\"text-sm text-gray-400\">\n                {connections.hasTikTok\n                  ? \"TikTok Connected\"\n                  : \"TikTok Disconnected\"}\n              </span>\n            </div>\n            <a\n              href=\"/api/tiktok/oauth/start\"\n              className=\"px-4 py-2 bg-gray-700 hover:bg-gray-600 rounded text-sm\"\n            >\n              {connections.hasTikTok ? \"Reconnect TikTok\" : \"Connect TikTok\"}\n            </a>\n            {connections.hasCookies && connections.cookiesLastUsedAt && (\n              <span className=\"text-xs text-gray-500\">\n                Last used:{\" \"}\n                {new Date(connections.cookiesLastUsedAt).toLocaleDateString()}\n              </span>\n            )}\n            <Link\n              href=\"/setup-cookies\"\n              className=\"px-4 py-2 bg-gray-700 hover:bg-gray-600 rounded text-sm\"\n            >\n              Update Cookies\n            </Link>\n            <button\n              onClick={handleLogout}\n              className=\"px-4 py-2 bg-gray-700 hover:bg-gray-600 rounded text-sm\"\n            >\n              Logout\n            </button>\n          </div>\n        </div>\n\n        {!connections.hasCookies && (\n          <div className=\"mb-6 p-4 bg-yellow-900/50 border border-yellow-700 rounded-lg\">\n            <p className=\"text-yellow-200 text-sm\">\n              YouTube cookies not configured. Please{\" \"}\n              <Link href=\"/setup-cookies\" className=\"underline\">\n                upload your cookies\n              </Link>{\" \"}\n              to submit videos.\n            </p>\n          </div>\n        )}\n\n        <div className=\"bg-gray-800 p-6 rounded-lg mb-8\">\n          <h2 className=\"text-xl font-semibold mb-4\">Submit YouTube Video</h2>\n          <form onSubmit={handleSubmit} className=\"flex gap-4\">\n            <input\n              type=\"text\"\n              value={url}\n              onChange={(e) => setUrl(e.target.value)}\n              placeholder=\"Enter YouTube URL\"\n              className=\"flex-1 px-4 py-2 bg-gray-700 rounded border border-gray-600 focus:outline-none focus:border-blue-500\"\n              disabled={loading || !connections.hasCookies}\n            />\n            <button\n              type=\"submit\"\n              disabled={loading || !url || !connections.hasCookies}\n              className=\"px-6 py-2 bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 rounded font-semibold\"\n            >\n              {loading ? \"Submitting...\" : \"Submit\"}\n            </button>\n          </form>\n          {error && (\n            <div className=\"mt-4 p-4 bg-red-900/50 border border-red-700 rounded-lg\">\n              <p className=\"text-red-200 text-sm mb-2\">{error}</p>\n              {(error.includes(\"cookies\") ||\n                error.includes(\"Sign in to confirm\")) && (\n                <Link\n                  href=\"/setup-cookies\"\n                  className=\"inline-block mt-2 px-4 py-2 bg-blue-600 hover:bg-blue-700 rounded text-sm\"\n                >\n                  Update YouTube Cookies\n                </Link>\n              )}\n            </div>\n          )}\n        </div>\n\n        <div className=\"bg-gray-800 p-6 rounded-lg\">\n          <h2 className=\"text-xl font-semibold mb-4\">Videos</h2>\n          <div className=\"overflow-x-auto\">\n            <table className=\"w-full\">\n              <thead>\n                <tr className=\"border-b border-gray-700\">\n                  <th className=\"text-left py-2 px-4\">Title</th>\n                  <th className=\"text-left py-2 px-4\">Status</th>\n                  <th className=\"text-left py-2 px-4\">Clips</th>\n                  <th className=\"text-left py-2 px-4\">Duration</th>\n                  <th className=\"text-left py-2 px-4\">Created</th>\n                  <th className=\"text-left py-2 px-4\">Actions</th>\n                </tr>\n              </thead>\n              <tbody>\n                {videos.map((video) => (\n                  <tr key={video.id} className=\"border-b border-gray-700\">\n                    <td className=\"py-3 px-4\">{video.title}</td>\n                    <td className=\"py-3 px-4\">\n                      <span\n                        className={`px-2 py-1 rounded text-xs ${\n                          video.status === \"completed\"\n                            ? \"bg-green-600\"\n                            : video.status === \"processing\"\n                              ? \"bg-blue-600\"\n                              : video.status === \"failed\"\n                                ? \"bg-red-600\"\n                                : \"bg-gray-600\"\n                        }`}\n                      >\n                        {video.status}\n                      </span>\n                    </td>\n                    <td className=\"py-3 px-4\">{video._count.clips}</td>\n                    <td className=\"py-3 px-4\">\n                      {Math.floor(video.durationSec / 60)}m\n                    </td>\n                    <td className=\"py-3 px-4\">\n                      {new Date(video.createdAt).toLocaleDateString()}\n                    </td>\n                    <td className=\"py-3 px-4\">\n                      <div className=\"flex gap-2\">\n                        <Link\n                          href={`/videos/${video.id}`}\n                          className=\"text-blue-400 hover:text-blue-300\"\n                        >\n                          View\n                        </Link>\n                        {video.status === \"processing\" && (\n                          <button\n                            onClick={() => handleCancel(video.id)}\n                            className=\"text-red-400 hover:text-red-300\"\n                          >\n                            Cancel\n                          </button>\n                        )}\n                      </div>\n                    </td>\n                  </tr>\n                ))}\n              </tbody>\n            </table>\n            {videos.length === 0 && (\n              <div className=\"text-center py-8 text-gray-400\">\n                No videos yet. Submit a YouTube URL to get started.\n              </div>\n            )}\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n","size_bytes":10264},"app/api/videos/route.ts":{"content":"import { NextRequest, NextResponse } from \"next/server\";\nimport { prisma } from \"@/src/lib/prisma\";\nimport { requireAuth } from \"@/src/lib/session\";\n\nfunction publicUrlForKey(key: string) {\n  const base = process.env.PUBLIC_ASSETS_BASE_URL || \"\";\n  if (base) {\n    return `${base.replace(/\\/$/, \"\")}/${key}`;\n  }\n  const endpoint = (process.env.S3_ENDPOINT || \"\").replace(/\\/$/, \"\");\n  const bucket = process.env.S3_BUCKET || \"\";\n  if (endpoint && bucket) {\n    return `${endpoint}/${bucket}/${key}`;\n  }\n  return \"\";\n}\n\nexport async function GET(request: NextRequest) {\n  try {\n    const session = await requireAuth();\n    if (!session.userId) {\n      return NextResponse.json(\n        { error: \"User ID not found in session\" },\n        { status: 401 },\n      );\n    }\n\n    const searchParams = request.nextUrl.searchParams;\n    const q = searchParams.get(\"q\") || \"\";\n    const page = Math.max(1, parseInt(searchParams.get(\"page\") || \"1\"));\n    const pageSize = Math.min(\n      100,\n      Math.max(1, parseInt(searchParams.get(\"pageSize\") || \"20\")),\n    );\n    const sort = searchParams.get(\"sort\") || \"createdAt\";\n    const include = searchParams.get(\"include\") || \"\";\n    const includeClips = include\n      .split(\",\")\n      .map((s) => s.trim())\n      .includes(\"clips\");\n\n    const where: any = { userId: session.userId };\n    if (q) {\n      where.OR = [\n        { title: { contains: q, mode: \"insensitive\" as const } },\n        { sourceUrl: { contains: q, mode: \"insensitive\" as const } },\n      ];\n    }\n\n    const orderBy =\n      sort === \"createdAt\"\n        ? { createdAt: \"desc\" as const }\n        : { updatedAt: \"desc\" as const };\n\n    const [videos, total] = await Promise.all([\n      prisma.video.findMany({\n        where,\n        orderBy,\n        skip: (page - 1) * pageSize,\n        take: pageSize,\n        include: includeClips\n          ? {\n              clips: {\n                orderBy: { createdAt: \"desc\" },\n                select: {\n                  id: true,\n                  startSec: true,\n                  endSec: true,\n                  durationSec: true,\n                  scoreOverall: true,\n                  s3VideoKey: true,\n                  s3ThumbKey: true,\n                  tiktokStatus: true,\n                  tiktokPublishId: true,\n                  createdAt: true,\n                },\n              },\n              _count: { select: { clips: true } },\n            }\n          : {\n              _count: { select: { clips: true } },\n            },\n      }),\n      prisma.video.count({ where }),\n    ]);\n\n    const shaped = includeClips\n      ? videos.map((v) => ({\n          ...v,\n          clips: v.clips.map((c) => ({\n            ...c,\n            videoUrl: publicUrlForKey(c.s3VideoKey),\n            thumbUrl: publicUrlForKey(c.s3ThumbKey),\n          })),\n        }))\n      : videos;\n\n    return NextResponse.json({\n      videos: shaped,\n      total,\n      page,\n      pageSize,\n      totalPages: Math.ceil(total / pageSize),\n    });\n  } catch (error: any) {\n    console.error(\"Error fetching videos:\", error);\n    if (error.message === \"Authentication required\") {\n      return NextResponse.json(\n        { error: \"Authentication required\" },\n        { status: 401 },\n      );\n    }\n    return NextResponse.json(\n      { error: \"Failed to fetch videos\" },\n      { status: 500 },\n    );\n  }\n}\n","size_bytes":3339},"src/lib/cleanup.ts":{"content":"import { existsSync, readdirSync, rmSync } from 'fs'\nimport { join } from 'path'\nimport { tmpdir } from 'os'\n\nexport function cleanupTempFiles(): void {\n  const tmp = tmpdir()\n  \n  const cookieDir = join(tmp, 'yt-cookies')\n  if (existsSync(cookieDir))\n  {\n    try {\n      for (const file of readdirSync(cookieDir))\n      {\n        const filePath = join(cookieDir, file)\n        try {\n          rmSync(filePath, { force: true })\n        }\n        catch (err) {\n          console.error(`Failed to remove cookie file ${file}:`, err)\n        }\n      }\n      console.log('Cleaned up temp cookie files')\n    }\n    catch (err) {\n      console.error('Failed to cleanup cookie directory:', err)\n    }\n  }\n  \n  try {\n    const files = readdirSync(tmp)\n    let cleaned = 0\n    for (const file of files)\n    {\n      if (file.match(/\\.(webm|mp4|m4a|part)$/))\n      {\n        const filePath = join(tmp, file)\n        try {\n          rmSync(filePath, { force: true })\n          cleaned++\n        }\n        catch (err) {\n          console.error(`Failed to remove temp file ${file}:`, err)\n        }\n      }\n    }\n    if (cleaned > 0)\n    {\n      console.log(`Cleaned up ${cleaned} temp video files`)\n    }\n  }\n  catch (err) {\n    console.error('Failed to cleanup temp directory:', err)\n  }\n}\n","size_bytes":1276},"src/services/framingService.ts":{"content":"import * as tf from '@tensorflow/tfjs-node'\nimport * as faceapi from '@vladmandic/face-api/dist/face-api.node.js'\nimport * as path from 'path'\nimport * as fs from 'fs'\nimport { execFile } from 'child_process'\nimport { promisify } from 'util'\n\nconst execFileAsync = promisify(execFile)\n\ntype TranscriptWord = { t: number; end: number; text: string; speaker?: string }\ntype SpeakerWindow = { start: number; end: number; speakerId: string }\ntype FaceBox = { t: number; x: number; y: number; w: number; h: number; landmarks?: number[][] }\ntype BodyBox = { x: number; y: number; w: number; h: number; cx: number; cy: number }\ntype FaceTrack = { id: string; boxes: FaceBox[] }\ntype CropKF = { t: number; x: number; y: number; w: number; h: number }\n\nlet modelsLoaded = false\n\nasync function ensureModelsLoaded(): Promise<void> {\n  if (modelsLoaded)\n  {\n    return\n  }\n  \n  await tf.setBackend('tensorflow')\n  await tf.enableProdMode()\n  await tf.ready()\n  \n  const modelPath = path.join(process.cwd(), 'models')\n  \n  if (!fs.existsSync(modelPath))\n  {\n    throw new Error(`Face detection models not found at ${modelPath}`)\n  }\n  \n  await faceapi.nets.ssdMobilenetv1.loadFromDisk(modelPath)\n  await faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath)\n  \n  modelsLoaded = true\n  console.log('Face detection models loaded successfully')\n}\n\nexport interface ComputeInput {\n  videoPath: string\n  baseW: number\n  baseH: number\n  segStart: number\n  segEnd: number\n  transcript: TranscriptWord[]\n}\n\nexport interface Constraints {\n  margin: number\n  maxPan: number\n  easeMs: number\n  centerBiasY: number\n  safeTop: number\n  safeBottom: number\n}\n\nexport async function computeCropMap(input: ComputeInput, c: Constraints): Promise<CropKF[] | null> {\n  const speaker = buildSpeakerTimeline(input.transcript, input.segStart, input.segEnd)\n  \n  if (speaker.length === 0)\n  {\n    return null\n  }\n  \n  const faces = await detectAndTrackFaces(input.videoPath, input.segStart, input.segEnd, input.baseW, input.baseH)\n  \n  if (faces.length === 0)\n  {\n    return null\n  }\n  \n  const mapping = mapSpeakersToTracks(speaker, faces)\n  \n  if (mapping.length === 0)\n  {\n    return null\n  }\n  \n  const raw = buildKeyframes(mapping, faces, input.baseW, input.baseH, c)\n  const smoothed = smoothAndConstrain(raw, input.baseW, input.baseH, input.segStart, input.segEnd, c)\n  \n  if (smoothed.length === 0)\n  {\n    return null\n  }\n  \n  return smoothed\n}\n\nfunction buildSpeakerTimeline(words: TranscriptWord[], segStart: number, segEnd: number): SpeakerWindow[] {\n  const win: SpeakerWindow[] = []\n  let cur = null as SpeakerWindow | null\n  \n  for (const w of words)\n  {\n    if (w.t < segStart)\n    {\n      continue\n    }\n    \n    if (w.t > segEnd)\n    {\n      break\n    }\n    \n    const sp = w.speaker ?? 'spk'\n    \n    if (!cur)\n    {\n      cur = { start: Math.max(w.t, segStart), end: Math.min(w.end, segEnd), speakerId: sp }\n      continue\n    }\n    \n    if (cur.speakerId === sp)\n    {\n      cur.end = Math.min(w.end, segEnd)\n    }\n    else\n    {\n      if (cur.end - cur.start > 0)\n      {\n        win.push(cur)\n      }\n      cur = { start: Math.max(w.t, segStart), end: Math.min(w.end, segEnd), speakerId: sp }\n    }\n  }\n  \n  if (cur && cur.end - cur.start > 0)\n  {\n    win.push(cur)\n  }\n  \n  return mergeShortWindows(win)\n}\n\nfunction mergeShortWindows(w: SpeakerWindow[]): SpeakerWindow[] {\n  if (w.length === 0)\n  {\n    return w\n  }\n  \n  const minHold = Number(process.env.FRAMING_MIN_SPEAKER_HOLD_MS || 600) / 1000\n  const out: SpeakerWindow[] = []\n  let cur = w[0]\n  \n  for (let i = 1; i < w.length; i++)\n  {\n    const nxt = w[i]\n    \n    if (nxt.start - cur.end < minHold && nxt.speakerId === cur.speakerId)\n    {\n      cur.end = nxt.end\n    }\n    else\n    {\n      out.push(cur)\n      cur = nxt\n    }\n  }\n  \n  out.push(cur)\n  \n  return out.filter(s => s.end - s.start >= minHold)\n}\n\nasync function detectAndTrackFaces(videoPath: string, segStart: number, segEnd: number, origW: number, origH: number): Promise<FaceTrack[]> {\n  try\n  {\n    await ensureModelsLoaded()\n    \n    const sampleFps = Number(process.env.FRAMING_SAMPLE_FPS || 3)\n    const duration = segEnd - segStart\n    const frameInterval = 1 / sampleFps\n    const frameCount = Math.ceil(duration * sampleFps)\n    const sampledFrameWidth = 640\n    \n    const frames: Array<{ t: number; tensor: tf.Tensor3D }> = []\n    const tempDir = path.join(process.cwd(), 'tmp', `frames_${Date.now()}`)\n    fs.mkdirSync(tempDir, { recursive: true })\n    \n    try\n    {\n      await extractFrames(videoPath, segStart, segEnd, sampleFps, tempDir)\n      \n      const frameFiles = fs.readdirSync(tempDir).filter(f => f.endsWith('.jpg')).sort()\n      \n      for (let i = 0; i < frameFiles.length && i < frameCount; i++)\n      {\n        const framePath = path.join(tempDir, frameFiles[i])\n        const imageBuffer = fs.readFileSync(framePath)\n        const decoded = tf.node.decodeImage(imageBuffer, 3) as tf.Tensor3D\n        const t = segStart + i * frameInterval\n        frames.push({ t, tensor: decoded })\n      }\n      \n      const detections: Array<{ t: number; faces: faceapi.WithFaceLandmarks<{ detection: faceapi.FaceDetection }>[] }> = []\n      const options = new faceapi.SsdMobilenetv1Options({ minConfidence: 0.6 })\n      \n      for (const frame of frames)\n      {\n        const result = await faceapi.detectAllFaces(frame.tensor as any, options).withFaceLandmarks()\n        detections.push({ t: frame.t, faces: result })\n      }\n      \n      const sampledHeight = frames.length > 0 ? frames[0].tensor.shape[0] : origH\n      const sampledWidth = frames.length > 0 ? frames[0].tensor.shape[1] : origW\n      \n      frames.forEach(f => f.tensor.dispose())\n      \n      const scaleX = origW / sampledWidth\n      const scaleY = origH / sampledHeight\n      \n      const tracks = buildFaceTracks(detections, scaleX, scaleY)\n      return tracks\n    }\n    finally\n    {\n      if (fs.existsSync(tempDir))\n      {\n        fs.rmSync(tempDir, { recursive: true, force: true })\n      }\n    }\n  }\n  catch (error)\n  {\n    console.error('Face detection failed:', error)\n    return []\n  }\n}\n\nasync function extractFrames(videoPath: string, segStart: number, segEnd: number, fps: number, outputDir: string): Promise<void> {\n  const duration = segEnd - segStart\n  const ffmpegPath = require('ffmpeg-static')\n  \n  await execFileAsync(ffmpegPath, [\n    '-ss', segStart.toFixed(3),\n    '-i', videoPath,\n    '-t', duration.toFixed(3),\n    '-vf', `fps=${fps},scale=640:-1`,\n    '-q:v', '2',\n    path.join(outputDir, 'frame_%04d.jpg')\n  ])\n}\n\nfunction buildFaceTracks(detections: Array<{ t: number; faces: faceapi.WithFaceLandmarks<{ detection: faceapi.FaceDetection }>[] }>, scaleX: number, scaleY: number): FaceTrack[] {\n  const tracks: FaceTrack[] = []\n  const maxDistance = 150 * scaleX\n  \n  for (const det of detections)\n  {\n    for (const face of det.faces)\n    {\n      const box = face.detection.box\n      const scaledBox = {\n        x: box.x * scaleX,\n        y: box.y * scaleY,\n        width: box.width * scaleX,\n        height: box.height * scaleY\n      }\n      const center = { x: scaledBox.x + scaledBox.width / 2, y: scaledBox.y + scaledBox.height / 2 }\n      \n      const landmarks = face.landmarks.positions.map(p => [p.x * scaleX, p.y * scaleY])\n      \n      let matched = false\n      \n      for (const track of tracks)\n      {\n        if (track.boxes.length === 0)\n        {\n          continue\n        }\n        \n        const lastBox = track.boxes[track.boxes.length - 1]\n        const lastCenter = { x: lastBox.x + lastBox.w / 2, y: lastBox.y + lastBox.h / 2 }\n        const dist = Math.sqrt(Math.pow(center.x - lastCenter.x, 2) + Math.pow(center.y - lastCenter.y, 2))\n        \n        if (dist < maxDistance)\n        {\n          track.boxes.push({\n            t: det.t,\n            x: Math.round(scaledBox.x),\n            y: Math.round(scaledBox.y),\n            w: Math.round(scaledBox.width),\n            h: Math.round(scaledBox.height),\n            landmarks\n          })\n          matched = true\n          break\n        }\n      }\n      \n      if (!matched)\n      {\n        tracks.push({\n          id: `track_${tracks.length}`,\n          boxes: [{\n            t: det.t,\n            x: Math.round(scaledBox.x),\n            y: Math.round(scaledBox.y),\n            w: Math.round(scaledBox.width),\n            h: Math.round(scaledBox.height),\n            landmarks\n          }]\n        })\n      }\n    }\n  }\n  \n  return tracks.filter(t => t.boxes.length >= 2)\n}\n\nfunction mapSpeakersToTracks(s: SpeakerWindow[], tracks: FaceTrack[]): Array<{ start: number; end: number; trackId: string }> {\n  const out: Array<{ start: number; end: number; trackId: string }> = []\n  \n  for (const sw of s)\n  {\n    let best = null as { id: string; overlap: number } | null\n    \n    for (const t of tracks)\n    {\n      const ov = overlapSeconds(sw.start, sw.end, t.boxes[0]?.t ?? 0, t.boxes[t.boxes.length - 1]?.t ?? 0)\n      \n      if (!best || ov > best.overlap)\n      {\n        best = { id: t.id, overlap: ov }\n      }\n    }\n    \n    if (best && best.overlap > 0)\n    {\n      out.push({ start: sw.start, end: sw.end, trackId: best.id })\n    }\n  }\n  \n  return out\n}\n\nfunction overlapSeconds(a: number, b: number, c: number, d: number): number {\n  const x = Math.max(a, c)\n  const y = Math.min(b, d)\n  \n  if (y <= x)\n  {\n    return 0\n  }\n  \n  return y - x\n}\n\nlet cachedTorsoMultiplier: number | null = null\n\nfunction getTorsoMultiplier(): number {\n  if (cachedTorsoMultiplier === null)\n  {\n    const val = parseFloat(process.env.FRAMING_TORSO_MULTIPLIER || '2.7')\n    cachedTorsoMultiplier = isNaN(val) || val <= 0 ? 2.7 : val\n  }\n  \n  return cachedTorsoMultiplier\n}\n\nfunction estimateBodyBox(faceBox: FaceBox, baseW: number, baseH: number): BodyBox | null {\n  if (!faceBox.landmarks || faceBox.landmarks.length < 68)\n  {\n    return null\n  }\n  \n  const lm = faceBox.landmarks\n  \n  const chinY = lm[8][1]\n  const eyebrowTopY = Math.min(lm[19][1], lm[24][1])\n  const headHeight = chinY - eyebrowTopY\n  \n  if (headHeight <= 0 || !isFinite(headHeight))\n  {\n    return null\n  }\n  \n  const jawLeft = lm[0]\n  const jawRight = lm[16]\n  const shoulderWidth = Math.abs(jawRight[0] - jawLeft[0]) * 1.8\n  \n  if (!isFinite(shoulderWidth) || shoulderWidth <= 0)\n  {\n    return null\n  }\n  \n  const torsoMultiplier = getTorsoMultiplier()\n  const torsoHeight = headHeight * torsoMultiplier\n  \n  const estimatedTopY = eyebrowTopY - headHeight * 0.2\n  const estimatedBottomY = Math.min(chinY + torsoHeight, baseH)\n  \n  const bodyHeight = estimatedBottomY - estimatedTopY\n  const centerX = (jawLeft[0] + jawRight[0]) / 2\n  const centerY = estimatedTopY + bodyHeight * 0.4\n  \n  if (!isFinite(centerX) || !isFinite(centerY))\n  {\n    return null\n  }\n  \n  const bodyLeft = Math.max(0, centerX - shoulderWidth / 2)\n  const bodyRight = Math.min(baseW, centerX + shoulderWidth / 2)\n  const bodyWidth = bodyRight - bodyLeft\n  \n  return {\n    x: bodyLeft,\n    y: estimatedTopY,\n    w: bodyWidth,\n    h: bodyHeight,\n    cx: centerX,\n    cy: centerY\n  }\n}\n\nfunction buildKeyframes(mapping: Array<{ start: number; end: number; trackId: string }>, tracks: FaceTrack[], baseW: number, baseH: number, c: Constraints): CropKF[] {\n  const out: CropKF[] = []\n  const targetW = Math.floor(baseH * 9 / 16)\n  const targetH = baseH\n  \n  for (const m of mapping)\n  {\n    const tr = tracks.find(t => t.id === m.trackId)\n    \n    if (!tr)\n    {\n      continue\n    }\n    \n    for (const b of tr.boxes)\n    {\n      if (b.t < m.start)\n      {\n        continue\n      }\n      \n      if (b.t > m.end)\n      {\n        break\n      }\n      \n      const bodyBox = estimateBodyBox(b, baseW, baseH)\n      \n      let cx: number\n      let cy: number\n      \n      if (bodyBox)\n      {\n        cx = bodyBox.cx\n        cy = bodyBox.cy - targetH * c.centerBiasY\n      }\n      else\n      {\n        cx = b.x + b.w / 2\n        cy = b.y + b.h * (0.5 - c.centerBiasY)\n      }\n      \n      let x = Math.round(cx - targetW / 2)\n      let y = Math.round(cy - targetH / 2)\n      \n      x = Math.max(0, Math.min(x, baseW - targetW))\n      \n      const safeTop = Math.round(targetH * c.safeTop)\n      const safeBottom = Math.round(targetH * c.safeBottom)\n      \n      y = Math.max(-safeTop, Math.min(y, baseH - targetH + safeBottom))\n      \n      out.push({ t: b.t, x, y, w: targetW, h: targetH })\n    }\n  }\n  \n  return dedupeByTime(out, 0.1)\n}\n\nfunction dedupeByTime(kf: CropKF[], minDelta: number): CropKF[] {\n  if (kf.length === 0)\n  {\n    return kf\n  }\n  \n  const out: CropKF[] = [kf[0]]\n  \n  for (let i = 1; i < kf.length; i++)\n  {\n    if (kf[i].t - out[out.length - 1].t >= minDelta)\n    {\n      out.push(kf[i])\n    }\n  }\n  \n  return out\n}\n\nfunction smoothAndConstrain(kf: CropKF[], baseW: number, baseH: number, segStart: number, segEnd: number, c: Constraints): CropKF[] {\n  if (kf.length === 0)\n  {\n    return kf\n  }\n  \n  const win = 3\n  const sm: CropKF[] = []\n  \n  for (let i = 0; i < kf.length; i++)\n  {\n    let sx = 0\n    let sy = 0\n    let n = 0\n    \n    for (let j = Math.max(0, i - win); j <= Math.min(kf.length - 1, i + win); j++)\n    {\n      sx += kf[j].x\n      sy += kf[j].y\n      n += 1\n    }\n    \n    const x = Math.round(sx / n)\n    const y = Math.round(sy / n)\n    sm.push({ t: kf[i].t, x, y, w: kf[i].w, h: kf[i].h })\n  }\n  \n  const out: CropKF[] = [sm[0]]\n  \n  for (let i = 1; i < sm.length; i++)\n  {\n    const dt = Math.max(0.001, sm[i].t - sm[i - 1].t)\n    const dx = sm[i].x - out[out.length - 1].x\n    const dy = sm[i].y - out[out.length - 1].y\n    const maxStep = Math.round(c.maxPan * dt)\n    const nx = stepLimit(out[out.length - 1].x, sm[i].x, maxStep)\n    const ny = stepLimit(out[out.length - 1].y, sm[i].y, maxStep)\n    out.push({ t: sm[i].t, x: nx, y: ny, w: sm[i].w, h: sm[i].h })\n  }\n  \n  return easeSpeakerEdges(out, segStart, segEnd, c.easeMs / 1000)\n}\n\nfunction stepLimit(a: number, b: number, m: number): number {\n  if (Math.abs(b - a) <= m)\n  {\n    return b\n  }\n  \n  if (b > a)\n  {\n    return a + m\n  }\n  \n  return a - m\n}\n\nfunction easeSpeakerEdges(kf: CropKF[], segStart: number, segEnd: number, easeS: number): CropKF[] {\n  if (kf.length < 2)\n  {\n    return kf\n  }\n  \n  const out: CropKF[] = [kf[0]]\n  \n  for (let i = 1; i < kf.length; i++)\n  {\n    const t = kf[i].t\n    const p = out[out.length - 1]\n    const fromStart = Math.min(1, Math.max(0, (t - segStart) / easeS))\n    const fromEnd = Math.min(1, Math.max(0, (segEnd - t) / easeS))\n    const alpha = Math.min(fromStart, fromEnd)\n    const x = Math.round(p.x + (kf[i].x - p.x) * alpha)\n    const y = Math.round(p.y + (kf[i].y - p.y) * alpha)\n    out.push({ t, x, y, w: kf[i].w, h: kf[i].h })\n  }\n  \n  return out\n}\n\nexport function buildPiecewiseExpr(kf: CropKF[], key: 'x' | 'y'): string {\n  if (kf.length === 0)\n  {\n    return '0'\n  }\n  \n  const parts: string[] = []\n  \n  const firstVal = key === 'x' ? kf[0].x : kf[0].y\n  parts.push(`lt(t,${kf[0].t.toFixed(3)})*${firstVal.toFixed(0)}`)\n  \n  for (let i = 0; i < kf.length - 1; i++)\n  {\n    const a = kf[i]\n    const b = kf[i + 1]\n    const ta = a.t\n    const tb = b.t\n    const va = key === 'x' ? a.x : a.y\n    const vb = key === 'x' ? b.x : b.y\n    const slope = (vb - va) / Math.max(0.001, tb - ta)\n    const expr = `between(t,${ta.toFixed(3)},${tb.toFixed(3)})*(${va.toFixed(0)}+(${slope.toFixed(6)})*(t-${ta.toFixed(3)}))`\n    parts.push(expr)\n  }\n  \n  const last = key === 'x' ? kf[kf.length - 1].x : kf[kf.length - 1].y\n  parts.push(`gte(t,${kf[kf.length - 1].t.toFixed(3)})*${last.toFixed(0)}`)\n  \n  return parts.join('+')\n}\n","size_bytes":15515},"scripts/retry-video.ts":{"content":"import { videoQueue } from '../src/lib/queue'\n\nconst videoId = process.argv[2]\nconst userId = process.argv[3]\n\nif (!videoId || !userId)\n{\n  console.error('Usage: ts-node scripts/retry-video.ts <videoId> <userId>')\n  process.exit(1)\n}\n\nasync function retry() {\n  try {\n    await videoQueue.add('process', {\n      videoId,\n      userId\n    })\n    console.log(`Job added to queue for video ${videoId}`)\n    process.exit(0)\n  }\n  catch (error) {\n    console.error('Error adding job:', error)\n    process.exit(1)\n  }\n}\n\nretry()\n","size_bytes":523},"app/api/tiktok/oauth/callback/route.ts":{"content":"import { NextRequest, NextResponse } from \"next/server\";\nimport { prisma } from \"@/src/lib/prisma\";\nimport { encrypt } from \"@/src/lib/encryption\";\nimport { getCurrentUserId } from \"@/src/lib/session\";\n\nfunction redirectAbs(req: NextRequest, path: string) {\n  const xfProto = req.headers.get(\"x-forwarded-proto\") || \"https\";\n  const xfHost = req.headers.get(\"x-forwarded-host\") || req.headers.get(\"host\");\n  const origin = xfHost ? `${xfProto}://${xfHost}` : req.nextUrl.origin;\n  return NextResponse.redirect(new URL(path, origin));\n}\n\nexport async function GET(req: NextRequest) {\n  try {\n    const { searchParams } = new URL(req.url);\n    const err = searchParams.get(\"error\");\n    if (err) {\n      return redirectAbs(req, \"/?tiktok=error\");\n    }\n    const code = searchParams.get(\"code\");\n    if (!code) {\n      return redirectAbs(req, \"/?tiktok=error_no_code\");\n    }\n\n    const body = new URLSearchParams();\n    body.set(\"client_key\", process.env.TIKTOK_CLIENT_KEY || \"\");\n    body.set(\"client_secret\", process.env.TIKTOK_CLIENT_SECRET || \"\");\n    body.set(\"code\", code);\n    body.set(\"grant_type\", \"authorization_code\");\n    body.set(\"redirect_uri\", process.env.TIKTOK_REDIRECT_URI || \"\");\n\n    const resp = await fetch(\"https://open.tiktokapis.com/v2/oauth/token/\", {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/x-www-form-urlencoded\" },\n      body,\n    });\n    const data = await resp.json();\n    if (!resp.ok) {\n      return redirectAbs(req, \"/?tiktok=error_exchange\");\n    }\n\n    const userId = await getCurrentUserId();\n    if (!userId) {\n      return redirectAbs(req, \"/login?error=1\");\n    }\n\n    const accessToken = data?.access_token as string | undefined;\n    const refreshToken = data?.refresh_token as string | undefined;\n    const openId = data?.open_id as string | undefined;\n    const expiresIn = Number(data?.expires_in || 0);\n    if (!accessToken || !refreshToken || !openId || !expiresIn) {\n      return redirectAbs(req, \"/?tiktok=error_payload\");\n    }\n\n    const expiresAt = new Date(Date.now() + expiresIn * 1000);\n    await prisma.tikTokConnection.upsert({\n      where: { openId },\n      update: {\n        userId,\n        accessToken: encrypt(accessToken),\n        refreshToken: encrypt(refreshToken),\n        scopes: Array.isArray(data.scope)\n          ? data.scope.join(\",\")\n          : data.scope || \"\",\n        expiresAt,\n      },\n      create: {\n        userId,\n        openId,\n        accessToken: encrypt(accessToken),\n        refreshToken: encrypt(refreshToken),\n        scopes: Array.isArray(data.scope)\n          ? data.scope.join(\",\")\n          : data.scope || \"\",\n        expiresAt,\n      },\n    });\n\n    return redirectAbs(req, \"/?tiktok=connected\");\n  } catch {\n    return redirectAbs(req, \"/?tiktok=error_500\");\n  }\n}\n","size_bytes":2787},"src/server/tiktokAuth.ts":{"content":"import { prisma } from \"@/src/lib/prisma\";\nimport { encrypt, decrypt } from \"@/src/lib/encryption\";\n\nexport async function getTikTokAccessTokenByUserId(userId: string) {\n  const row = await prisma.tikTokConnection.findFirst({ where: { userId } });\n  if (!row) {\n    return null;\n  }\n  if (Date.now() < row.expiresAt.getTime()) {\n    return decrypt(row.accessToken);\n  }\n  const body = new URLSearchParams();\n  body.set(\"client_key\", process.env.TIKTOK_CLIENT_KEY || \"\");\n  console.log(\"client_key\", process.env.TIKTOK_CLIENT_KEY);\n  body.set(\"client_secret\", process.env.TIKTOK_CLIENT_SECRET || \"\");\n  body.set(\"grant_type\", \"refresh_token\");\n  body.set(\"refresh_token\", decrypt(row.refreshToken));\n  const r = await fetch(\"https://open.tiktokapis.com/v2/oauth/token/\", {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/x-www-form-urlencoded\" },\n    body,\n  });\n  const data = await r.json();\n  if (!data.access_token) {\n    return null;\n  }\n  const expiresAt = new Date(Date.now() + data.expires_in * 1000);\n  await prisma.tikTokConnection.update({\n    where: { id: row.id },\n    data: {\n      accessToken: encrypt(data.access_token),\n      refreshToken: encrypt(data.refresh_token || decrypt(row.refreshToken)),\n      expiresAt,\n    },\n  });\n  return data.access_token;\n}\n","size_bytes":1290},"app/api/tiktok/oauth/start/route.ts":{"content":"import { NextResponse } from \"next/server\";\n\nexport async function GET() {\n  const params = new URLSearchParams();\n  params.set(\"client_key\", process.env.TIKTOK_CLIENT_KEY || \"\");\n  params.set(\"response_type\", \"code\");\n  params.set(\"redirect_uri\", process.env.TIKTOK_REDIRECT_URI || \"\");\n  params.set(\"scope\", \"user.info.basic,video.upload\");\n  params.set(\"state\", crypto.randomUUID());\n  return NextResponse.redirect(\n    `https://www.tiktok.com/v2/auth/authorize/?${params.toString()}`,\n  );\n}\n","size_bytes":496},"src/services/tiktok.ts":{"content":"import { promises as fsp } from \"fs\";\nimport { Readable } from \"stream\";\n\ntype EnsureTokenInput = {\n  accessToken: string;\n  refreshToken: string;\n  expiresAt: Date;\n};\n\ntype EnsureTokenOutput = {\n  accessToken: string;\n  refreshToken: string;\n  expiresAt: Date;\n  rotated: boolean;\n};\n\nasync function throwIfNotOk(res: Response, label: string) {\n  if (res.ok) {\n    return;\n  }\n  let body: any = null;\n  try {\n    body = await res.json();\n  } catch {}\n  const detail = body ? JSON.stringify(body) : await res.text().catch(() => \"\");\n  throw new Error(`${label} ${res.status} ${detail}`);\n}\n\nexport async function ensureAccessToken(\n  input: EnsureTokenInput,\n): Promise<EnsureTokenOutput> {\n  const now = Date.now();\n  const exp = input.expiresAt ? input.expiresAt.getTime() : 0;\n  if (exp - now > 120000) {\n    return {\n      accessToken: input.accessToken,\n      refreshToken: input.refreshToken,\n      expiresAt: input.expiresAt,\n      rotated: false,\n    };\n  }\n  const res = await fetch(\"https://open.tiktokapis.com/v2/oauth/token/\", {\n    method: \"POST\",\n    headers: { \"content-type\": \"application/x-www-form-urlencoded\" },\n    body: new URLSearchParams({\n      client_key: process.env.TIKTOK_CLIENT_KEY as string,\n      client_secret: process.env.TIKTOK_CLIENT_SECRET as string,\n      grant_type: \"refresh_token\",\n      refresh_token: input.refreshToken,\n    }),\n  });\n  await throwIfNotOk(res, \"tiktok refresh failed\");\n  if (!res.ok) {\n    throw new Error(`tiktok refresh failed ${res.status}`);\n  }\n  const j = await res.json();\n  const at = j.access_token as string;\n  const rt = (j.refresh_token as string) || input.refreshToken;\n  const expiresIn = Number(j.expires_in || 3600);\n  const until = new Date(Date.now() + expiresIn * 1000);\n  return { accessToken: at, refreshToken: rt, expiresAt: until, rotated: true };\n}\n\ntype InitUploadInput = {\n  accessToken: string;\n  mode: \"draft\" | \"publish\";\n};\n\ntype InitUploadOutput = {\n  uploadUrl: string;\n  publishId: string;\n};\n\nexport async function initUpload(\n  input: InitUploadInput,\n): Promise<InitUploadOutput> {\n  const res = await fetch(\n    \"https://open.tiktokapis.com/v2/post/publish/video/init/\",\n    {\n      method: \"POST\",\n      headers: {\n        authorization: `Bearer ${input.accessToken}`,\n        \"content-type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        post_info: {\n          title: \"\",\n          visibility: input.mode === \"draft\" ? \"self_only\" : \"public\",\n        },\n        source_info: { source: \"UPLOAD\" },\n      }),\n    },\n  );\n  await throwIfNotOk(res, \"tiktok init failed\");\n  if (!res.ok) {\n    throw new Error(`tiktok init failed ${res.status}`);\n  }\n  const j = await res.json();\n  const uploadUrl = j.data?.upload_url as string;\n  const publishId = j.data?.publish_id as string;\n  if (!uploadUrl || !publishId) {\n    throw new Error(\"tiktok init missing upload_url or publish_id\");\n  }\n  return { uploadUrl, publishId };\n}\n\nimport { createReadStream } from \"fs\";\n\ntype UploadToUrlInput = {\n  uploadUrl: string;\n  filePath: string;\n};\n\nexport async function uploadToUrl(input: UploadToUrlInput) {\n  const stat = await fsp.stat(input.filePath);\n  const nodeStream = createReadStream(input.filePath);\n  const webStream = Readable.toWeb(\n    nodeStream,\n  ) as unknown as ReadableStream<Uint8Array>;\n\n  const res = await fetch(input.uploadUrl, {\n    method: \"PUT\",\n    body: webStream,\n    headers: {\n      \"Content-Type\": \"video/mp4\",\n      \"Content-Length\": String(stat.size),\n      Expect: \"100-continue\",\n    },\n  });\n  await throwIfNotOk(res, \"tiktok upload failed\");\n  if (!res.ok) {\n    throw new Error(`tiktok upload failed ${res.status}`);\n  }\n}\n\ntype PublishVideoInput = {\n  accessToken: string;\n  publishId: string;\n  caption: string;\n  mode: \"draft\" | \"publish\";\n};\n\ntype PublishVideoOutput = {\n  ok: boolean;\n};\n\nexport async function publishVideo(\n  input: PublishVideoInput,\n): Promise<PublishVideoOutput> {\n  const res = await fetch(\n    \"https://open.tiktokapis.com/v2/post/publish/video/\",\n    {\n      method: \"POST\",\n      headers: {\n        authorization: `Bearer ${input.accessToken}`,\n        \"content-type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        publish_id: input.publishId,\n        post_info: {\n          title: input.caption,\n          visibility: input.mode === \"draft\" ? \"self_only\" : \"public\",\n          disable_duet: true,\n          disable_stitch: true,\n          disable_comment: false,\n        },\n      }),\n    },\n  );\n  await throwIfNotOk(res, \"tiktok publish failed\");\n\n  if (!res.ok) {\n    throw new Error(`tiktok publish failed ${res.status}`);\n  }\n  return { ok: true };\n}\n","size_bytes":4651},"app/api/tiktok/clip/[id]/post/route.ts":{"content":"import { NextRequest, NextResponse } from \"next/server\";\nimport { prisma } from \"@/src/lib/prisma\";\nimport { getCurrentUserId } from \"@/src/lib/session\";\nimport { Queue } from \"bullmq\";\nimport { connection } from \"@/src/lib/queue\";\n\nconst tiktokQueue = new Queue(\"tiktok.post\", { connection });\n\nexport async function POST(\n  req: NextRequest,\n  { params }: { params: { id: string } },\n) {\n  const userId = await getCurrentUserId();\n  if (!userId) {\n    return NextResponse.json({ ok: false }, { status: 401 });\n  }\n  const body = await req.json();\n  const mode = body?.mode;\n  if (mode !== \"draft\" && mode !== \"publish\") {\n    return NextResponse.json({ ok: false }, { status: 400 });\n  }\n  const clip = await prisma.clip.findFirst({\n    where: { id: params.id, Video: { userId } },\n  });\n  if (!clip) {\n    return NextResponse.json({ ok: false }, { status: 404 });\n  }\n  await tiktokQueue.add(\"post\", { userId, clipId: clip.id, mode });\n  return NextResponse.json({ ok: true });\n}\n","size_bytes":983},"app/api/videos/[id]/retry/route.ts":{"content":"import { NextRequest, NextResponse } from 'next/server'\nimport { requireAuth } from '@/src/lib/session'\nimport { prisma } from '@/src/lib/prisma'\nimport { videoQueue } from '@/src/lib/queue'\n\nexport async function POST(\n  request: NextRequest,\n  { params }: { params: { id: string } }\n) {\n  try {\n    const session = await requireAuth()\n    const { id } = params\n    \n    const video = await prisma.video.findUnique({\n      where: { id, userId: session.userId }\n    })\n    \n    if (!video)\n    {\n      return NextResponse.json({ error: 'Video not found' }, { status: 404 })\n    }\n    \n    if (video.status === 'completed')\n    {\n      return NextResponse.json({ error: 'Video already completed' }, { status: 400 })\n    }\n    \n    const job = await videoQueue.getJob(id)\n    \n    if (job)\n    {\n      await job.remove()\n    }\n    \n    await prisma.video.update({\n      where: { id },\n      data: { status: 'queued' }\n    })\n    \n    await videoQueue.add('process', {\n      videoId: video.id,\n      userId: session.userId\n    })\n    \n    return NextResponse.json({ success: true, status: 'queued' })\n  }\n  catch (error) {\n    console.error('Error retrying video:', error)\n    return NextResponse.json({ error: 'Failed to retry video' }, { status: 500 })\n  }\n}\n","size_bytes":1258},"app/components/tiktokPostButtons.tsx":{"content":"\"use client\";\nimport { useState } from \"react\";\n\nexport function TikTokPostButtons({ clipId }: { clipId: string }) {\n  const [loading, setLoading] = useState<null | \"draft\" | \"publish\">(null);\n  async function send(mode: \"draft\" | \"publish\") {\n    setLoading(mode);\n    await fetch(`/api/tiktok/clip/${clipId}/post`, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({ mode }),\n    });\n    setLoading(null);\n  }\n  return (\n    <div className=\"flex gap-2\">\n      <button\n        onClick={() => send(\"draft\")}\n        disabled={loading !== null}\n        className=\"rounded-2xl px-3 py-2 border\"\n      >\n        {loading === \"draft\" ? \"Sending...\" : \"Post as Draft\"}\n      </button>\n      <button\n        onClick={() => send(\"publish\")}\n        disabled={loading !== null}\n        className=\"rounded-2xl px-3 py-2 border\"\n      >\n        {loading === \"publish\" ? \"Sending...\" : \"Publish\"}\n      </button>\n    </div>\n  );\n}\n","size_bytes":976},"src/services/segmentation-v2.ts":{"content":"import { TranscriptSegment, TranscriptWord } from './openai'\nimport { SceneChange } from './ffmpeg'\nimport { Chapter } from './youtube'\n\nexport interface EnhancedSegment {\n  startSec: number\n  endSec: number\n  durationSec: number\n  words: TranscriptWord[]\n  text: string\n  hook: string\n  score: number\n  features: SegmentFeatures\n  rationaleShort: string\n  durationChoice: 'short30' | 'mid45' | 'long60'\n  chapterTitle?: string\n}\n\nexport interface SegmentFeatures {\n  hookScore: number\n  retentionScore: number\n  clarityScore: number\n  visualScore: number\n  noveltyScore: number\n  engagementScore: number\n  safetyScore: number\n  speechRate: number\n  pauseDensity: number\n  energyLevel: number\n  hasQuestion: boolean\n  hasBoldClaim: boolean\n  hasNumbers: boolean\n  sceneChangeCount: number\n  wordCount: number\n}\n\nexport interface CommentHotspot {\n  timeSec: number\n  density: number\n}\n\nexport function mineTimestampsFromComments(comments: { text: string }[]): number[] {\n  const tsRe = /(?<!\\d)(\\d{1,2}):(\\d{2})(?::(\\d{2}))?(?!\\d)/g\n  const marks: number[] = []\n  \n  for (const c of comments) {\n    const matches = c.text.matchAll(tsRe)\n    for (const m of matches) {\n      const h = m[3] ? parseInt(m[1], 10) : 0\n      const mm = m[3] ? parseInt(m[2], 10) : parseInt(m[1], 10)\n      const ss = m[3] ? parseInt(m[3], 10) : parseInt(m[2], 10)\n      const sec = h * 3600 + mm * 60 + ss\n      marks.push(sec)\n    }\n  }\n  \n  return clusterPeaks(marks, 30)\n}\n\nfunction clusterPeaks(xs: number[], windowSec: number): number[] {\n  if (xs.length === 0)\n  {\n    return []\n  }\n  \n  const s = [...xs].sort((a, b) => a - b)\n  const peaks: number[] = []\n  let acc: number[] = []\n  \n  for (const x of s) {\n    if (acc.length === 0) {\n      acc.push(x)\n    } else {\n      const last = acc[acc.length - 1]\n      if (x - last <= windowSec) {\n        acc.push(x)\n      } else {\n        peaks.push(median(acc))\n        acc = [x]\n      }\n    }\n  }\n  \n  if (acc.length > 0) {\n    peaks.push(median(acc))\n  }\n  \n  return peaks\n}\n\nfunction median(xs: number[]): number {\n  if (xs.length === 0)\n  {\n    return 0\n  }\n  \n  const sorted = [...xs].sort((a, b) => a - b)\n  const m = Math.floor(sorted.length / 2)\n  return sorted.length % 2 ? sorted[m] : Math.floor((sorted[m - 1] + sorted[m]) / 2)\n}\n\nexport function generateChapterWindows(chapters: Chapter[], introIdx: number | null): Array<{ start: number; end: number; chapterTitle: string }> {\n  const ws: Array<{ start: number; end: number; chapterTitle: string }> = []\n  \n  for (let i = 0; i < chapters.length; i++) {\n    if (introIdx !== null && i === introIdx) {\n      continue\n    }\n    \n    const c = chapters[i]\n    const span = c.endSec - c.startSec\n    const step = Math.max(45, Math.floor(span * 0.1))\n    let t = c.startSec\n    \n    while (t + 25 <= c.endSec) {\n      ws.push({ \n        start: t, \n        end: Math.min(c.endSec, t + 75),\n        chapterTitle: c.title\n      })\n      t += step\n    }\n  }\n  \n  return ws\n}\n\nfunction detectHookPatterns(text: string): { hasQuestion: boolean; hasBoldClaim: boolean; hasNumbers: boolean } {\n  const hasQuestion = /^(how|what|why|when|where|who|can|will|should|is|are|do|does|did)\\s/i.test(text) || /\\?/.test(text)\n  \n  const boldClaimPatterns = [\n    /^(this is|here's|the best|the worst|never|always|you need|you must|don't|stop)/i,\n    /^(secret|truth|fact|proven|guaranteed|ultimate|perfect)/i,\n    /(vs\\.|versus|vs|compared to)/i,\n    /^(shocking|amazing|incredible|unbelievable)/i\n  ]\n  \n  const hasBoldClaim = boldClaimPatterns.some(p => p.test(text))\n  const hasNumbers = /\\b\\d+\\b/.test(text)\n  \n  return { hasQuestion, hasBoldClaim, hasNumbers }\n}\n\nfunction analyzeSpeechDynamics(words: TranscriptWord[], startSec: number): { rate: number; pauseDensity: number; energy: number } {\n  if (words.length === 0)\n  {\n    return { rate: 0, pauseDensity: 1, energy: 0 }\n  }\n  \n  const first5sWords = words.filter(w => w.start - startSec < 5)\n  \n  if (first5sWords.length === 0)\n  {\n    return { rate: 0, pauseDensity: 1, energy: 0 }\n  }\n  \n  const duration = Math.max(0.1, first5sWords[first5sWords.length - 1].end - first5sWords[0].start)\n  const rate = first5sWords.length / duration\n  \n  let totalGap = 0\n  for (let i = 0; i < first5sWords.length - 1; i++) {\n    totalGap += Math.max(0, first5sWords[i + 1].start - first5sWords[i].end)\n  }\n  const pauseDensity = totalGap / duration\n  \n  const energyWords = first5sWords.filter(w => \n    /[A-Z]{2,}/.test(w.word) || /[!?]/.test(w.word) || w.word.length > 8\n  ).length\n  const energy = energyWords / first5sWords.length\n  \n  return { rate, pauseDensity, energy }\n}\n\nfunction calculateSegmentFeatures(\n  words: TranscriptWord[], \n  startSec: number, \n  endSec: number,\n  sceneChanges: SceneChange[],\n  hotspots: number[]\n): SegmentFeatures {\n  const text = words.map(w => w.word).join(' ')\n  const hook = words.filter(w => w.start - startSec < 3).map(w => w.word).join(' ').trim()\n  \n  const { hasQuestion, hasBoldClaim, hasNumbers } = detectHookPatterns(hook || text.substring(0, 100))\n  const dynamics = analyzeSpeechDynamics(words, startSec)\n  \n  const sceneChangesInSegment = sceneChanges.filter(s => s.timeSec >= startSec && s.timeSec <= endSec).length\n  \n  let hookScore = 0.5\n  if (hasQuestion) hookScore += 0.2\n  if (hasBoldClaim) hookScore += 0.2\n  if (hasNumbers) hookScore += 0.1\n  if (dynamics.energy > 0.3) hookScore += 0.15\n  if (dynamics.rate > 2.5) hookScore += 0.1\n  hookScore = Math.min(1, hookScore)\n  \n  let retentionScore = 0.5\n  if (dynamics.rate > 2) retentionScore += 0.2\n  if (dynamics.pauseDensity < 0.2) retentionScore += 0.15\n  if (sceneChangesInSegment >= 2 && sceneChangesInSegment <= 4) retentionScore += 0.15\n  retentionScore = Math.min(1, retentionScore)\n  \n  const fillerWords = words.filter(w => /^(um|uh|like|you know|sort of|kind of)$/i.test(w.word.trim())).length\n  const clarityScore = Math.max(0, 1 - (fillerWords / Math.max(1, words.length)) * 2)\n  \n  const visualScore = sceneChangesInSegment >= 1 && sceneChangesInSegment <= 6 ? 0.8 : 0.5\n  \n  const noveltyScore = 0.6\n  \n  const nearHotspot = hotspots.some(h => Math.abs(h - startSec) < 30)\n  const engagementScore = nearHotspot ? 0.8 : 0.4\n  \n  const profanityPattern = /\\b(fuck|shit|damn|hell|ass|bitch)\\b/i\n  const safetyScore = profanityPattern.test(text) ? 0.3 : 0.9\n  \n  return {\n    hookScore,\n    retentionScore,\n    clarityScore,\n    visualScore,\n    noveltyScore,\n    engagementScore,\n    safetyScore,\n    speechRate: dynamics.rate,\n    pauseDensity: dynamics.pauseDensity,\n    energyLevel: dynamics.energy,\n    hasQuestion,\n    hasBoldClaim,\n    hasNumbers,\n    sceneChangeCount: sceneChangesInSegment,\n    wordCount: words.length\n  }\n}\n\nfunction scoreSegment(features: SegmentFeatures): number {\n  return (\n    0.28 * features.hookScore +\n    0.18 * features.retentionScore +\n    0.16 * features.clarityScore +\n    0.12 * features.visualScore +\n    0.10 * features.noveltyScore +\n    0.10 * features.engagementScore +\n    0.06 * features.safetyScore\n  )\n}\n\nfunction chooseDuration(features: SegmentFeatures, candidateDuration: number): { targetDuration: number; choice: 'short30' | 'mid45' | 'long60' } {\n  let prefer = 30\n  let choice: 'short30' | 'mid45' | 'long60' = 'short30'\n  \n  if (features.retentionScore > 0.7 && features.hookScore > 0.6) {\n    prefer = 45\n    choice = 'mid45'\n  }\n  \n  if (features.hookScore > 0.8 && features.retentionScore > 0.8) {\n    prefer = 60\n    choice = 'long60'\n  }\n  \n  if (features.clarityScore < 0.5) {\n    prefer = Math.min(prefer, 35)\n  }\n  \n  const target = Math.min(Math.max(20, prefer), candidateDuration)\n  \n  return { targetDuration: target, choice }\n}\n\nfunction generateRationale(features: SegmentFeatures, score: number): string {\n  const reasons: Array<{ text: string; value: number }> = []\n  \n  if (features.hookScore > 0.7) {\n    reasons.push({ text: 'strong hook', value: features.hookScore })\n  }\n  if (features.retentionScore > 0.7) {\n    reasons.push({ text: 'high retention potential', value: features.retentionScore })\n  }\n  if (features.clarityScore > 0.8) {\n    reasons.push({ text: 'clear message', value: features.clarityScore })\n  }\n  if (features.engagementScore > 0.7) {\n    reasons.push({ text: 'audience engagement hotspot', value: features.engagementScore })\n  }\n  if (features.hasQuestion) {\n    reasons.push({ text: 'question hook', value: 0.8 })\n  }\n  if (features.hasBoldClaim) {\n    reasons.push({ text: 'bold claim', value: 0.75 })\n  }\n  if (features.sceneChangeCount >= 2 && features.sceneChangeCount <= 4) {\n    reasons.push({ text: 'good visual pacing', value: 0.7 })\n  }\n  \n  const top3 = reasons.sort((a, b) => b.value - a.value).slice(0, 3).map(r => r.text)\n  \n  if (top3.length === 0)\n  {\n    return `Segment scored ${(score * 100).toFixed(0)}/100`\n  }\n  \n  return `Strong because: ${top3.join(', ')}`\n}\n\nexport function detectEnhancedSegments(\n  transcript: TranscriptSegment[],\n  sceneChanges: SceneChange[],\n  chapters: Chapter[],\n  videoDuration: number,\n  commentHotspots: number[] = []\n): EnhancedSegment[] {\n  const allWords: TranscriptWord[] = []\n  \n  for (const segment of transcript) {\n    for (const word of segment.words) {\n      allWords.push(word)\n    }\n  }\n  \n  if (allWords.length === 0) {\n    return []\n  }\n  \n  const detectedLanguage = transcript[0]?.language\n  const introIdx = findIntroChapterIndex(chapters, detectedLanguage)\n  \n  const windows = chapters.length > 0 \n    ? generateChapterWindows(chapters, introIdx)\n    : [{ start: 180, end: videoDuration || allWords[allWords.length - 1].end, chapterTitle: 'Main Content' }]\n  \n  const candidates: EnhancedSegment[] = []\n  \n  for (const window of windows) {\n    const windowWords = allWords.filter(w => w.start >= window.start && w.start < window.end)\n    \n    if (windowWords.length < 10)\n    {\n      continue\n    }\n    \n    const pauseBoundaries: number[] = [0]\n    \n    for (let i = 0; i < windowWords.length - 1; i++) {\n      const gap = windowWords[i + 1].start - windowWords[i].end\n      \n      if (gap >= 0.35 && gap <= 1.2) {\n        pauseBoundaries.push(i + 1)\n      }\n    }\n    \n    pauseBoundaries.push(windowWords.length)\n    \n    for (let i = 0; i < pauseBoundaries.length - 1; i++) {\n      for (let j = i + 1; j < pauseBoundaries.length; j++) {\n        const segWords = windowWords.slice(pauseBoundaries[i], pauseBoundaries[j])\n        \n        if (segWords.length < 8)\n        {\n          continue\n        }\n        \n        const startSec = segWords[0].start\n        const endSec = segWords[segWords.length - 1].end\n        const duration = endSec - startSec\n        \n        if (duration < 20 || duration > 75)\n        {\n          continue\n        }\n        \n        const features = calculateSegmentFeatures(segWords, startSec, endSec, sceneChanges, commentHotspots)\n        const score = scoreSegment(features)\n        \n        if (score < 0.5)\n        {\n          continue\n        }\n        \n        const { targetDuration, choice } = chooseDuration(features, duration)\n        const adjustedEndSec = Math.min(endSec, startSec + targetDuration)\n        const adjustedWords = segWords.filter(w => w.end <= adjustedEndSec)\n        \n        if (adjustedWords.length < 8)\n        {\n          continue\n        }\n        \n        const text = adjustedWords.map(w => w.word).join(' ')\n        const hook = adjustedWords.filter(w => w.start - startSec < 3).map(w => w.word).join(' ').trim()\n        const rationale = generateRationale(features, score)\n        \n        candidates.push({\n          startSec,\n          endSec: adjustedEndSec,\n          durationSec: adjustedEndSec - startSec,\n          words: adjustedWords,\n          text,\n          hook: hook || text.substring(0, 50),\n          score,\n          features,\n          rationaleShort: rationale,\n          durationChoice: choice,\n          chapterTitle: window.chapterTitle\n        })\n      }\n    }\n  }\n  \n  const qualityFiltered = applyQualityGuards(candidates)\n  const diversified = applyDiversityFilter(qualityFiltered, 0.7)\n  const nonOverlapping = removeOverlaps(diversified)\n  \n  return nonOverlapping.slice(0, 12)\n}\n\nfunction findIntroChapterIndex(chapters: Chapter[], detectedLanguage?: string): number | null {\n  if (chapters.length === 0)\n  {\n    return null\n  }\n  \n  const introKeywords: Record<string, string[]> = {\n    'en': ['intro', 'introduction', 'opening', 'welcome'],\n    'es': ['intro', 'introduccion', 'introducción', 'apertura', 'inicio'],\n    'pt': ['intro', 'introducao', 'introdução', 'apresentação', 'abertura'],\n    'fr': ['intro', 'introduction', 'ouverture'],\n    'de': ['intro', 'einführung', 'einleitung'],\n  }\n  \n  const keywordsToCheck = detectedLanguage && introKeywords[detectedLanguage] \n    ? introKeywords[detectedLanguage] \n    : Object.values(introKeywords).flat()\n  \n  const firstTitle = chapters[0].title.toLowerCase()\n  \n  for (const kw of keywordsToCheck) {\n    if (firstTitle.includes(kw))\n    {\n      return 0\n    }\n  }\n  \n  return null\n}\n\nfunction applyQualityGuards(segments: EnhancedSegment[]): EnhancedSegment[] {\n  return segments.filter(seg => {\n    const first3sWords = seg.words.filter(w => w.start - seg.startSec < 3)\n    \n    if (first3sWords.length < 3)\n    {\n      return false\n    }\n    \n    if (seg.features.safetyScore < 0.5)\n    {\n      return false\n    }\n    \n    if (seg.features.clarityScore < 0.3)\n    {\n      return false\n    }\n    \n    return true\n  })\n}\n\nfunction applyDiversityFilter(segments: EnhancedSegment[], threshold: number): EnhancedSegment[] {\n  if (segments.length === 0)\n  {\n    return []\n  }\n  \n  const sorted = [...segments].sort((a, b) => b.score - a.score)\n  const selected: EnhancedSegment[] = [sorted[0]]\n  \n  for (let i = 1; i < sorted.length; i++) {\n    let tooSimilar = false\n    \n    for (const existing of selected) {\n      const similarity = textSimilarity(sorted[i].text, existing.text)\n      \n      if (similarity > threshold) {\n        tooSimilar = true\n        break\n      }\n    }\n    \n    if (!tooSimilar) {\n      selected.push(sorted[i])\n    }\n  }\n  \n  return selected\n}\n\nfunction textSimilarity(a: string, b: string): number {\n  const wordsA = new Set(a.toLowerCase().split(/\\s+/))\n  const wordsB = new Set(b.toLowerCase().split(/\\s+/))\n  \n  let intersection = 0\n  for (const word of wordsA) {\n    if (wordsB.has(word)) {\n      intersection++\n    }\n  }\n  \n  const union = wordsA.size + wordsB.size - intersection\n  \n  if (union === 0)\n  {\n    return 0\n  }\n  \n  return intersection / union\n}\n\nfunction hasOverlap(seg1: EnhancedSegment, seg2: EnhancedSegment): boolean {\n  return !(seg1.endSec <= seg2.startSec || seg2.endSec <= seg1.startSec)\n}\n\nfunction removeOverlaps(segments: EnhancedSegment[]): EnhancedSegment[] {\n  if (segments.length === 0)\n  {\n    return []\n  }\n  \n  const sorted = [...segments].sort((a, b) => b.score - a.score)\n  const selected: EnhancedSegment[] = []\n  \n  for (const segment of sorted) {\n    let overlaps = false\n    \n    for (const existing of selected) {\n      if (hasOverlap(segment, existing)) {\n        overlaps = true\n        break\n      }\n    }\n    \n    if (!overlaps) {\n      selected.push(segment)\n    }\n  }\n  \n  return selected.sort((a, b) => a.startSec - b.startSec)\n}\n","size_bytes":15182},"src/worker-tiktok.ts":{"content":"import { Worker, Job } from \"bullmq\";\nimport { connection } from \"@/src/lib/queue\";\nimport { prisma } from \"@/src/lib/prisma\";\nimport { tmpdir } from \"os\";\nimport { join } from \"path\";\nimport { existsSync, mkdirSync, rmSync, createWriteStream } from \"fs\";\nimport { S3Client, GetObjectCommand } from \"@aws-sdk/client-s3\";\nimport { Readable } from \"stream\";\nimport { pipeline } from \"stream/promises\";\nimport { promises as fsp } from \"fs\";\n\nimport {\n  ensureAccessToken,\n  initUpload,\n  uploadToUrl,\n  publishVideo,\n} from \"@/src/services/tiktok\";\nimport { decrypt, encrypt } from \"@/src/lib/encryption\";\n\ntype TikTokJob = {\n  userId: string;\n  clipId: string;\n  mode: \"draft\" | \"publish\";\n};\n\nconst s3 = new S3Client({\n  region: process.env.S3_REGION as string,\n  endpoint: process.env.S3_ENDPOINT as string,\n  credentials: {\n    accessKeyId: process.env.S3_ACCESS_KEY_ID as string,\n    secretAccessKey: process.env.S3_SECRET_ACCESS_KEY as string,\n  },\n  forcePathStyle: true,\n});\n\nasync function downloadS3ToFile(key: string, outPath: string) {\n  const obj = await s3.send(\n    new GetObjectCommand({\n      Bucket: process.env.S3_BUCKET as string,\n      Key: key,\n    }),\n  );\n\n  const body = obj.Body as any;\n\n  if (!body) {\n    throw new Error(\"S3 body empty\");\n  }\n\n  const ws = createWriteStream(outPath);\n\n  if (typeof body.pipe === \"function\") {\n    await pipeline(body as NodeJS.ReadableStream, ws);\n    return;\n  }\n\n  if (typeof body.transformToWebStream === \"function\") {\n    const web = body.transformToWebStream();\n    await pipeline(Readable.fromWeb(web as any), ws);\n    return;\n  }\n\n  if (typeof body.getReader === \"function\") {\n    await pipeline(Readable.fromWeb(body as any), ws);\n    return;\n  }\n\n  if (typeof body.arrayBuffer === \"function\") {\n    const buf = Buffer.from(await body.arrayBuffer());\n    await fsp.writeFile(outPath, buf);\n    return;\n  }\n\n  throw new Error(\"Unsupported S3 body type\");\n}\n\nfunction buildCaption(\n  customTitle: string | null,\n  customDescription: string | null,\n  fallbackTitle: string | null,\n  hook: string | null,\n  tags: string[] | null,\n) {\n  if (customTitle || customDescription) {\n    const parts = [customTitle, customDescription].filter(Boolean);\n    const tagStr = (tags || [])\n      .slice(0, 6)\n      .map((t) => (t.startsWith(\"#\") ? t : `#${t}`))\n      .join(\" \");\n    const full = [...parts, tagStr].filter(Boolean).join(\" \").trim();\n    if (full.length <= 200) {\n      return full;\n    }\n    return full.slice(0, 200);\n  }\n  const base = [hook || \"\", fallbackTitle || \"\"].filter(Boolean).join(\" · \").trim();\n  const tagStr = (tags || [])\n    .slice(0, 6)\n    .map((t) => (t.startsWith(\"#\") ? t : `#${t}`))\n    .join(\" \");\n  const full = [base, tagStr].filter(Boolean).join(\" \").trim();\n  if (full.length <= 200) {\n    return full;\n  }\n  return full.slice(0, 200);\n}\n\nasync function processTikTok(job: Job<TikTokJob>) {\n  const { userId, clipId, mode } = job.data;\n\n  if (!userId) {\n    throw new Error(\"userId is required\");\n  }\n\n  if (!clipId) {\n    throw new Error(\"clipId is required\");\n  }\n\n  if (!(mode === \"draft\" || mode === \"publish\")) {\n    throw new Error(\"invalid mode\");\n  }\n\n  const conn = await prisma.tikTokConnection.findFirst({\n    where: { userId },\n    orderBy: { updatedAt: \"desc\" },\n  });\n\n  if (!conn) {\n    throw new Error(\"tiktok connection not found\");\n  }\n\n  const clip = await prisma.clip.findUnique({\n    where: { id: clipId },\n    select: {\n      id: true,\n      s3VideoKey: true,\n      rationaleShort: true,\n      tags: true,\n      tiktokTitle: true,\n      tiktokDescription: true,\n      Video: { select: { title: true } },\n    },\n  });\n\n  if (!clip) {\n    throw new Error(\"clip not found\");\n  }\n\n  if (!clip.s3VideoKey) {\n    throw new Error(\"clip s3VideoKey missing\");\n  }\n\n  const ensured = await ensureAccessToken({\n    accessToken: decrypt(conn.accessToken),\n    refreshToken: decrypt(conn.refreshToken),\n    expiresAt: conn.expiresAt,\n  });\n\n  if (ensured.rotated) {\n    await prisma.tikTokConnection.update({\n      where: { id: conn.id },\n      data: {\n        accessToken: encrypt(ensured.accessToken),\n        refreshToken: encrypt(ensured.refreshToken),\n        expiresAt: ensured.expiresAt,\n      },\n    });\n  }\n\n  const workDir = join(tmpdir(), `tiktok_${clipId}`);\n  if (!existsSync(workDir)) {\n    mkdirSync(workDir, { recursive: true });\n  }\n\n  const filePath = join(workDir, \"clip.mp4\");\n  await downloadS3ToFile(clip.s3VideoKey, filePath);\n\n  const init = await initUpload({\n    accessToken: ensured.accessToken,\n    mode,\n  });\n\n  await uploadToUrl({\n    uploadUrl: init.uploadUrl,\n    filePath,\n  });\n\n  const caption = buildCaption(\n    clip.tiktokTitle || null,\n    clip.tiktokDescription || null,\n    clip.Video?.title || null,\n    clip.rationaleShort || null,\n    (clip.tags as string[]) || [],\n  );\n\n  await publishVideo({\n    accessToken: ensured.accessToken,\n    publishId: init.publishId,\n    caption,\n    mode,\n  });\n\n  await prisma.clip.update({\n    where: { id: clipId },\n    data: {\n      tiktokPublishId: init.publishId,\n      tiktokStatus: mode === \"draft\" ? \"draft\" : \"published\",\n    },\n  });\n\n  rmSync(workDir, { recursive: true, force: true });\n\n  return { publishId: init.publishId };\n}\n\nexport const tiktokWorker = new Worker<TikTokJob>(\n  \"tiktok.post\",\n  processTikTok,\n  {\n    connection,\n    concurrency: 2,\n    lockDuration: 600000,\n    lockRenewTime: 30000,\n    maxStalledCount: 1,\n  },\n);\n\ntiktokWorker.on(\"completed\", (job) => {\n  console.log(`tiktok.post ${job.id} completed`);\n});\n\ntiktokWorker.on(\"failed\", async (job, err) => {\n  if (job?.data?.clipId) {\n    await prisma.clip\n      .update({\n        where: { id: job.data.clipId },\n        data: { tiktokStatus: \"failed\" },\n      })\n      .catch(() => {});\n  }\n  console.error(`tiktok.post ${job?.id} failed`, err);\n});\n","size_bytes":5819}},"version":2}